{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "- import various helpers, load data, select reviews by status and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from application.name_obj_classes import PubName, PersonName, remove_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.review_obj_class import ReviewObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.text_preprocessing import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "import database.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aps_details_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_review = ReviewObj(aps_details_single[1].record_id, aps_details_single[1].full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Demonstrations and Instantiations\n",
    "\n",
    "- Classify review/not review\n",
    "- Classify single_focus, multi_focus\n",
    "- With only single_focus, extract information such as the title of the book being reviewed, the assumed gender of the author, the assumed genre and/or subgenre of the book, the reported publisher, and the price\n",
    "- Do this as a closed set problem, using fuzzy matching, clustering, and maybe a reinforcement learning or deep learning\n",
    "- Do this as an open set problem, or as a problem where \"not in the set\" is possible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In NYTBR section, Book Review or Not Book Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A NEW ESSAYIST.; C.F.G. Masterman, M.P., Criticises Kipling and Other British Institutions.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_rows[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4242, 4327)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need more non-review content\n",
    "nyt_not_review = [i for i in nyt_rows if i[12] == 'not_review']\n",
    "nyt_review = [i for i in nyt_rows if i[12] in ('multi', 'cluster', 'really_multi', 'single_focus')]\n",
    "len(nyt_review), len(nyt_not_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATEST PUBLICATIONS  Books Received During the Week Ended July 25 Classified and Annotated According'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I2mos = [i for i in nyt_not_review if 'I2mo' in i[4]]\n",
    "I2mos[1][4][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_full_txt = [i[4] for i in nyt_review] + [i[4] for i in nyt_not_review]\n",
    "# make \"true labels\" (0s and 1s so scikit learn can score them)\n",
    "labels = [0 for i in range(len(nyt_review))] + [1 for i in range(len(nyt_not_review))]\n",
    "len(list_of_full_txt) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import various from scikit learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# set up logistic regression with gender labels\n",
    "v = CountVectorizer()\n",
    "X = v.fit_transform(list_of_full_txt)\n",
    "tfidf = TfidfTransformer()\n",
    "Z = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rows into training data, training labels, test data, and test labels\n",
    "# test on 33% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z, labels, test_size=0.33, random_state=12)\n",
    "\n",
    "# instantiate the model and fit to the training data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make label predictions\n",
    "results = lr.predict(X_test)\n",
    "\n",
    "# generate probabilities for each label\n",
    "probs = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': {'f1': 0.884814942926323, 'precision': 0.8498338870431894, 'recall': 0.9227994227994228}, 'not_review': {'f1': 0.8795660036166365, 'precision': 0.9191232048374905, 'recall': 0.8432732316227461}, 'accuracy': 0.8822489391796322}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "# generate f1, precision, recall, and accuracy scores\n",
    "# I will discuss each of these in the lesson\n",
    "for y,z in [(\"review\",0),(\"not_review\",1)]:\n",
    "    scores[y] = {}\n",
    "    scores[y][\"f1\"] = f1_score(y_test, results, pos_label=z, average='binary')  \n",
    "    scores[y][\"precision\"] = precision_score(y_test, results, pos_label=z, average='binary')\n",
    "    scores[y][\"recall\"] = recall_score(y_test, results, pos_label=z, average='binary')\n",
    "\n",
    "scores[\"accuracy\"] = accuracy_score(y_test, results)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = []\n",
    "coefs = []\n",
    "for key,val in v.vocabulary_.items():\n",
    "    terms.append(key)\n",
    "    coefs.append(lr.coef_[0][val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pp</td>\n",
       "      <td>-5.146061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>-3.361216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>-2.945701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>her</td>\n",
       "      <td>-2.848645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>volume</td>\n",
       "      <td>-2.781168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>she</td>\n",
       "      <td>-2.397521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>with</td>\n",
       "      <td>-2.388235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>tile</td>\n",
       "      <td>-2.328123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>reader</td>\n",
       "      <td>-2.254851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>12mo</td>\n",
       "      <td>-2.213153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>chapter</td>\n",
       "      <td>-2.054118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>his</td>\n",
       "      <td>-1.916618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>ill</td>\n",
       "      <td>-1.837196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>all</td>\n",
       "      <td>-1.799856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.725866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>pages</td>\n",
       "      <td>-1.540068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>history</td>\n",
       "      <td>-1.485525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>is</td>\n",
       "      <td>-1.446554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>so</td>\n",
       "      <td>-1.433299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>which</td>\n",
       "      <td>-1.403423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>man</td>\n",
       "      <td>-1.399809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>had</td>\n",
       "      <td>-1.394639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>of</td>\n",
       "      <td>-1.359994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>th</td>\n",
       "      <td>-1.329488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>their</td>\n",
       "      <td>-1.326744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>these</td>\n",
       "      <td>-1.275521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>cloth</td>\n",
       "      <td>-1.275065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>human</td>\n",
       "      <td>-1.205001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>life</td>\n",
       "      <td>-1.192520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>those</td>\n",
       "      <td>-1.191721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term      coef\n",
       "0        pp -5.146061\n",
       "1        he -3.361216\n",
       "2       and -2.945701\n",
       "3       her -2.848645\n",
       "4    volume -2.781168\n",
       "5       she -2.397521\n",
       "6      with -2.388235\n",
       "7      tile -2.328123\n",
       "8    reader -2.254851\n",
       "9      12mo -2.213153\n",
       "10  chapter -2.054118\n",
       "11      his -1.916618\n",
       "12      ill -1.837196\n",
       "13      all -1.799856\n",
       "14       50 -1.725866\n",
       "15    pages -1.540068\n",
       "16  history -1.485525\n",
       "17       is -1.446554\n",
       "18       so -1.433299\n",
       "19    which -1.403423\n",
       "20      man -1.399809\n",
       "21      had -1.394639\n",
       "22       of -1.359994\n",
       "23       th -1.329488\n",
       "24    their -1.326744\n",
       "25    these -1.275521\n",
       "26    cloth -1.275065\n",
       "27    human -1.205001\n",
       "28     life -1.192520\n",
       "29    those -1.191721"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this block produces a dataframe with the top 30 terms associated with label 0\n",
    "df_coef = pd.DataFrame()\n",
    "df_coef['term'] = terms\n",
    "df_coef['coef'] = coefs\n",
    "df_coef = df_coef.sort_values(by='coef').reset_index(drop=True)\n",
    "df_coef.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>408132</td>\n",
       "      <td>literary</td>\n",
       "      <td>1.966858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408133</td>\n",
       "      <td>number</td>\n",
       "      <td>2.005087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408134</td>\n",
       "      <td>has</td>\n",
       "      <td>2.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408135</td>\n",
       "      <td>publishers</td>\n",
       "      <td>2.025496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408136</td>\n",
       "      <td>magazine</td>\n",
       "      <td>2.029833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408137</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>2.068803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408138</td>\n",
       "      <td>performance</td>\n",
       "      <td>2.113786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408139</td>\n",
       "      <td>l2mo</td>\n",
       "      <td>2.126622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408140</td>\n",
       "      <td>london</td>\n",
       "      <td>2.154999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408141</td>\n",
       "      <td>times</td>\n",
       "      <td>2.157221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408142</td>\n",
       "      <td>article</td>\n",
       "      <td>2.236704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408143</td>\n",
       "      <td>at</td>\n",
       "      <td>2.278984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408144</td>\n",
       "      <td>saturday</td>\n",
       "      <td>2.279148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408145</td>\n",
       "      <td>last</td>\n",
       "      <td>2.508893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408146</td>\n",
       "      <td>music</td>\n",
       "      <td>2.538258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408147</td>\n",
       "      <td>me</td>\n",
       "      <td>2.578978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408148</td>\n",
       "      <td>exhibition</td>\n",
       "      <td>2.592475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408149</td>\n",
       "      <td>readers</td>\n",
       "      <td>2.731123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408150</td>\n",
       "      <td>review</td>\n",
       "      <td>2.770367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408151</td>\n",
       "      <td>poem</td>\n",
       "      <td>2.777325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408152</td>\n",
       "      <td>issue</td>\n",
       "      <td>2.793155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408153</td>\n",
       "      <td>in</td>\n",
       "      <td>2.972769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408154</td>\n",
       "      <td>new</td>\n",
       "      <td>3.092456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408155</td>\n",
       "      <td>be</td>\n",
       "      <td>3.135520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408156</td>\n",
       "      <td>week</td>\n",
       "      <td>3.209241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408157</td>\n",
       "      <td>play</td>\n",
       "      <td>3.286714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408158</td>\n",
       "      <td>published</td>\n",
       "      <td>3.714079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408159</td>\n",
       "      <td>by</td>\n",
       "      <td>4.858057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408160</td>\n",
       "      <td>books</td>\n",
       "      <td>4.922154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408161</td>\n",
       "      <td>will</td>\n",
       "      <td>5.045089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term      coef\n",
       "408132     literary  1.966858\n",
       "408133       number  2.005087\n",
       "408134          has  2.006700\n",
       "408135   publishers  2.025496\n",
       "408136     magazine  2.029833\n",
       "408137    yesterday  2.068803\n",
       "408138  performance  2.113786\n",
       "408139         l2mo  2.126622\n",
       "408140       london  2.154999\n",
       "408141        times  2.157221\n",
       "408142      article  2.236704\n",
       "408143           at  2.278984\n",
       "408144     saturday  2.279148\n",
       "408145         last  2.508893\n",
       "408146        music  2.538258\n",
       "408147           me  2.578978\n",
       "408148   exhibition  2.592475\n",
       "408149      readers  2.731123\n",
       "408150       review  2.770367\n",
       "408151         poem  2.777325\n",
       "408152        issue  2.793155\n",
       "408153           in  2.972769\n",
       "408154          new  3.092456\n",
       "408155           be  3.135520\n",
       "408156         week  3.209241\n",
       "408157         play  3.286714\n",
       "408158    published  3.714079\n",
       "408159           by  4.858057\n",
       "408160        books  4.922154\n",
       "408161         will  5.045089"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view the top 30 terms associated with label 1, we look at the bottom rows of the same dataframe\n",
    "#I2mo ... pub announcements have both, but OCR may be of a lower quality with long lists and blurb announcements\n",
    "#or just more hances to get it wrong\n",
    "df_coef.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on aps_reviews\n",
    "# make predictions using nonbinary data \n",
    "aps_reviews = [i.full_text for i in aps_rows if i.review_type in ('single_focus', 'multi', 'cluster')]\n",
    "aps_ids = [i.record_id for i in aps_rows if i.review_type in ('single_focus', 'multi', 'cluster')]\n",
    "aps_urls = [\"https://aps-web-app.matthew-lavin.com/static/pdf/%s.pdf\"%i for i in aps_ids]\n",
    "\n",
    "aps_vectors = v.transform(aps_reviews)\n",
    "aps_tfidf = tfidf.fit_transform(aps_vectors)\n",
    "\n",
    "# generate probabilities for each label\n",
    "aps_probs = lr.predict_proba(aps_tfidf)\n",
    "\n",
    "#display the results as a pandas dataframe\n",
    "aps_results = pd.DataFrame()\n",
    "\n",
    "# make columns for the original label, the nyt_id, the cluster_id, the pdf url, and the predicted probabilities\n",
    "\n",
    "aps_results['aps_id'] = aps_ids\n",
    "aps_results['url'] = aps_urls\n",
    "aps_results['prob_review'] = [i[0] for i in aps_probs]\n",
    "aps_results['prob_not_review'] = [i[1] for i in aps_probs]\n",
    "len(aps_results.loc[aps_results['prob_review'] > 0.5].reset_index())/len(aps_results)\n",
    "#79.39% of aps reviews have a naive probability score over .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856345885634589"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this doesn't tell us how many false positives we might get, just that a model trained on NYT reviews usually recognizes APS reviews as reviews\n",
    "aps_not_reviews = [i.full_text for i in aps_rows if i.review_type == 'not_review']\n",
    "aps_non_review_ids = [i.record_id for i in aps_rows if i.review_type == 'not_review']\n",
    "aps_non_review_urls = [\"https://aps-web-app.matthew-lavin.com/static/pdf/%s.pdf\"%i for i in aps_non_review_ids]\n",
    "\n",
    "aps_non_review_vectors = v.transform(aps_not_reviews)\n",
    "aps_non_review_tfidf = tfidf.fit_transform(aps_non_review_vectors)\n",
    "\n",
    "# generate probabilities for each label\n",
    "aps_non_review_probs = lr.predict_proba(aps_non_review_tfidf)\n",
    "\n",
    "#display the results as a pandas dataframe\n",
    "aps_non_review_results = pd.DataFrame()\n",
    "\n",
    "# make columns for the original label, the nyt_id, the cluster_id, the pdf url, and the predicted probabilities\n",
    "\n",
    "aps_non_review_results['aps_id'] = aps_non_review_ids\n",
    "aps_non_review_results['url'] = aps_non_review_urls\n",
    "aps_non_review_results['prob_review'] = [i[0] for i in aps_non_review_probs]\n",
    "aps_non_review_results['prob_not_review'] = [i[1] for i in aps_non_review_probs]\n",
    "len(aps_non_review_results.loc[aps_non_review_results['prob_not_review'] > 0.5].reset_index())/len(aps_non_review_results)\n",
    "# 58.93% of non-reviews would have a non-review probability over 50%, so we might want to adjust to reduce false positives \n",
    "# However, say we started with a mix of 80/20 reviews and not reviews\n",
    "# If we got these results with 1000 objects, we would have 635 true postives, 165 false negatives, 118 true negatives and 82 false positives\n",
    "# If this were all true, we'd be running calculations on a sample that's 88.5% book reviews and 11.5% not\n",
    "# Pretty good, but we want better, especially the false positive\n",
    "# Option 1: improve the model with data, setup, or learning method (labor)\n",
    "# Option 2: raise the probability threshold to be considered a review (also creates more false negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-work vs. Multi-work Reviews\n",
    "\n",
    "- The exemplar of a single-work review is very clear, as is the exemplar of review that covers more than one \n",
    "- Complications and edge cases arise when it's predominantly a review of one book, with a section that compares it to another book, or in that there is a great variety to multi-work reviews. Some columns like \"Latest Fiction\" are scanned as separate single work reviews, some as one object. In general, I have found it desirable to isolate clear single-work reviews from others for information extraction or review classification tasks, but other methods wouldn't require this.\n",
    "- It may be desirable to target multi-work reviews if, for example, you want \"in the same review\" to be edge weights in a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps_single = [i for i in aps_rows if i.review_type == 'single_focus']\n",
    "aps_not_single = [i for i in aps_rows if i.review_type in ('multi', 'cluster')]\n",
    "#len(aps_single), len(aps_not_single) >>> (1003, 550)\n",
    "aps_list_of_full_txt = [i.full_text for i in aps_single] + [i.full_text for i in aps_not_single]\n",
    "# make \"true labels\" (0s and 1s so scikit learn can score them)\n",
    "aps_labels = [0 for i in range(len(aps_single))] + [1 for i in range(len(aps_not_single))]\n",
    "#len(aps_list_of_full_txt) == len(aps_labels) >>> True\n",
    "# set up logistic regression with gender labels\n",
    "v = CountVectorizer()\n",
    "X = v.fit_transform(aps_list_of_full_txt)\n",
    "tfidf = TfidfTransformer()\n",
    "Z = tfidf.fit_transform(X)\n",
    "\n",
    "# split the rows into training data, training labels, test data, and test labels\n",
    "# test on 33% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z, aps_labels, test_size=0.33, random_state=81)\n",
    "\n",
    "# instantiate the model and fit to the training data\n",
    "lr = LogisticRegression(class_weight={0:0.35, 1:0.65})\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make label predictions\n",
    "results = lr.predict(X_test)\n",
    "\n",
    "# generate probabilities for each label\n",
    "probs = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'single-work review': {'f1': 0.8204334365325077, 'precision': 0.8412698412698413, 'recall': 0.8006042296072508}, 'multi-work review': {'f1': 0.6947368421052631, 'precision': 0.6666666666666666, 'recall': 0.7252747252747253}, 'accuracy': 0.7738791423001949}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "# generate f1, precision, recall, and accuracy scores\n",
    "# I will discuss each of these in the lesson\n",
    "for y,z in [(\"single-work review\",0),(\"multi-work review\",1)]:\n",
    "    scores[y] = {}\n",
    "    scores[y][\"f1\"] = f1_score(y_test, results, pos_label=z, average='binary')  \n",
    "    scores[y][\"precision\"] = precision_score(y_test, results, pos_label=z, average='binary')\n",
    "    scores[y][\"recall\"] = recall_score(y_test, results, pos_label=z, average='binary')\n",
    "\n",
    "scores[\"accuracy\"] = accuracy_score(y_test, results)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>he</td>\n",
       "      <td>-0.721452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>his</td>\n",
       "      <td>-0.668302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>-0.667718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>-0.639716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>him</td>\n",
       "      <td>-0.435286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>not</td>\n",
       "      <td>-0.409498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>had</td>\n",
       "      <td>-0.405744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>were</td>\n",
       "      <td>-0.373912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>to</td>\n",
       "      <td>-0.308820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>as</td>\n",
       "      <td>-0.307325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>be</td>\n",
       "      <td>-0.300616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>would</td>\n",
       "      <td>-0.272713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>us</td>\n",
       "      <td>-0.264312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>you</td>\n",
       "      <td>-0.255627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>my</td>\n",
       "      <td>-0.248861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>did</td>\n",
       "      <td>-0.237361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>if</td>\n",
       "      <td>-0.227858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>when</td>\n",
       "      <td>-0.226263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>never</td>\n",
       "      <td>-0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>only</td>\n",
       "      <td>-0.221687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>can</td>\n",
       "      <td>-0.218413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>or</td>\n",
       "      <td>-0.209664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>lie</td>\n",
       "      <td>-0.203932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>all</td>\n",
       "      <td>-0.199105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>chapter</td>\n",
       "      <td>-0.198836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>where</td>\n",
       "      <td>-0.196822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>at</td>\n",
       "      <td>-0.193704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>upon</td>\n",
       "      <td>-0.185438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>great</td>\n",
       "      <td>-0.184933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>schouler</td>\n",
       "      <td>-0.184918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term      coef\n",
       "0         he -0.721452\n",
       "1        his -0.668302\n",
       "2       that -0.667718\n",
       "3        was -0.639716\n",
       "4        him -0.435286\n",
       "5        not -0.409498\n",
       "6        had -0.405744\n",
       "7       were -0.373912\n",
       "8         to -0.308820\n",
       "9         as -0.307325\n",
       "10        be -0.300616\n",
       "11     would -0.272713\n",
       "12        us -0.264312\n",
       "13       you -0.255627\n",
       "14        my -0.248861\n",
       "15       did -0.237361\n",
       "16        if -0.227858\n",
       "17      when -0.226263\n",
       "18     never -0.226000\n",
       "19      only -0.221687\n",
       "20       can -0.218413\n",
       "21        or -0.209664\n",
       "22       lie -0.203932\n",
       "23       all -0.199105\n",
       "24   chapter -0.198836\n",
       "25     where -0.196822\n",
       "26        at -0.193704\n",
       "27      upon -0.185438\n",
       "28     great -0.184933\n",
       "29  schouler -0.184918"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = []\n",
    "coefs = []\n",
    "for key,val in v.vocabulary_.items():\n",
    "    terms.append(key)\n",
    "    coefs.append(lr.coef_[0][val])\n",
    "\n",
    "# this block produces a dataframe with the top 30 terms associated with label 0\n",
    "df_coef = pd.DataFrame()\n",
    "df_coef['term'] = terms\n",
    "df_coef['coef'] = coefs\n",
    "df_coef = df_coef.sort_values(by='coef').reset_index(drop=True)\n",
    "df_coef.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69454</td>\n",
       "      <td>illustrated</td>\n",
       "      <td>0.441490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69455</td>\n",
       "      <td>edited</td>\n",
       "      <td>0.443003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69456</td>\n",
       "      <td>contains</td>\n",
       "      <td>0.451154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69457</td>\n",
       "      <td>edition</td>\n",
       "      <td>0.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69458</td>\n",
       "      <td>stories</td>\n",
       "      <td>0.482132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69459</td>\n",
       "      <td>boston</td>\n",
       "      <td>0.485738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69460</td>\n",
       "      <td>series</td>\n",
       "      <td>0.494175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69461</td>\n",
       "      <td>00</td>\n",
       "      <td>0.498977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69462</td>\n",
       "      <td>books</td>\n",
       "      <td>0.550457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69463</td>\n",
       "      <td>mr</td>\n",
       "      <td>0.553731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69464</td>\n",
       "      <td>25</td>\n",
       "      <td>0.562756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69465</td>\n",
       "      <td>volume</td>\n",
       "      <td>0.564269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69466</td>\n",
       "      <td>poems</td>\n",
       "      <td>0.567882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69467</td>\n",
       "      <td>are</td>\n",
       "      <td>0.582949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69468</td>\n",
       "      <td>illustrations</td>\n",
       "      <td>0.637125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69469</td>\n",
       "      <td>pp</td>\n",
       "      <td>0.650341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69470</td>\n",
       "      <td>50</td>\n",
       "      <td>0.660585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69471</td>\n",
       "      <td>price</td>\n",
       "      <td>0.665877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69472</td>\n",
       "      <td>cents</td>\n",
       "      <td>0.701436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69473</td>\n",
       "      <td>story</td>\n",
       "      <td>0.767137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69474</td>\n",
       "      <td>in</td>\n",
       "      <td>0.776416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69475</td>\n",
       "      <td>york</td>\n",
       "      <td>0.829119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69476</td>\n",
       "      <td>book</td>\n",
       "      <td>0.970012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69477</td>\n",
       "      <td>new</td>\n",
       "      <td>1.031195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69478</td>\n",
       "      <td>is</td>\n",
       "      <td>1.159626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69479</td>\n",
       "      <td>the</td>\n",
       "      <td>1.186988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69480</td>\n",
       "      <td>of</td>\n",
       "      <td>1.401769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69481</td>\n",
       "      <td>co</td>\n",
       "      <td>1.469271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69482</td>\n",
       "      <td>by</td>\n",
       "      <td>1.782722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69483</td>\n",
       "      <td>and</td>\n",
       "      <td>1.797663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                term      coef\n",
       "69454    illustrated  0.441490\n",
       "69455         edited  0.443003\n",
       "69456       contains  0.451154\n",
       "69457        edition  0.468600\n",
       "69458        stories  0.482132\n",
       "69459         boston  0.485738\n",
       "69460         series  0.494175\n",
       "69461             00  0.498977\n",
       "69462          books  0.550457\n",
       "69463             mr  0.553731\n",
       "69464             25  0.562756\n",
       "69465         volume  0.564269\n",
       "69466          poems  0.567882\n",
       "69467            are  0.582949\n",
       "69468  illustrations  0.637125\n",
       "69469             pp  0.650341\n",
       "69470             50  0.660585\n",
       "69471          price  0.665877\n",
       "69472          cents  0.701436\n",
       "69473          story  0.767137\n",
       "69474             in  0.776416\n",
       "69475           york  0.829119\n",
       "69476           book  0.970012\n",
       "69477            new  1.031195\n",
       "69478             is  1.159626\n",
       "69479            the  1.186988\n",
       "69480             of  1.401769\n",
       "69481             co  1.469271\n",
       "69482             by  1.782722\n",
       "69483            and  1.797663"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-fb6fbdfb8034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtitle_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mone_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaned_toks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_review' is not defined"
     ]
    }
   ],
   "source": [
    "#one_review.cleaned_toks\n",
    "#one_review.cleaned_text\n",
    "\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "title_candidates = [list(),]\n",
    "for token in one_review.cleaned_toks:\n",
    "    if token.istitle() or token in stopwords.words('english') or token in string.punctuation:\n",
    "        if len(title_candidates[-1]) > 0:\n",
    "            if token not in string.punctuation:\n",
    "                title_candidates[-1].append(token)\n",
    "        else:\n",
    "            if token.istitle():\n",
    "                title_candidates[-1].append(token)\n",
    "    else:\n",
    "        if len(title_candidates[-1]) > 0:\n",
    "            title_candidates.append(list())\n",
    "\n",
    "def remove_function_tail(sequence):\n",
    "    if sequence[-1].lower() in stopwords.words('english'):\n",
    "        sequence.pop()\n",
    "        return remove_function_tail(sequence)\n",
    "    else:\n",
    "        return sequence\n",
    "    \n",
    "candidates_tidy = []\n",
    "for sequence in title_candidates:\n",
    "    # rule out if all function words\n",
    "    all_function = True\n",
    "    for word in sequence:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            all_function = False\n",
    "            break\n",
    "    if all_function == False:\n",
    "        #remove function word tails recursively\n",
    "        sequence = remove_function_tail(sequence)\n",
    "        candidates_tidy.append(sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': {'f1': 0.7794994040524433, 'precision': 0.638671875, 'recall': 1.0}, 'not_review': {'f1': 0.010695187165775402, 'precision': 1.0, 'recall': 0.005376344086021506}, 'accuracy': 0.6393762183235867}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.65731842]]), array([[0.]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_focus[1].reviewed_book_title, candidates_tidy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts = []\n",
    "for i in candidates_tidy:\n",
    "    texts.extend(i)\n",
    "texts = [\" \".join(texts),]    \n",
    "texts.append(single_focus[1].reviewed_book_title)\n",
    "texts.append(single_focus[0].reviewed_book_title)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "vectors = X.toarray()\n",
    "\n",
    "cosine_similarity([vectors[0]], [vectors[1]]), cosine_similarity([vectors[0]], [vectors[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publisher Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pub_matches(match_list):\n",
    "    cleaned_matches = []\n",
    "    for match in match_list:\n",
    "        index_to_start = 0\n",
    "        for i, x in enumerate(match[1].split()):\n",
    "            if x[0].islower() and x[0]!='&':\n",
    "                index_to_start = i+1\n",
    "        cleaned_matches.append(' '.join(match[1].split()[index_to_start:]))\n",
    "    return cleaned_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dash_for_pub(pub_match):\n",
    "    return re.sub(r'(?<!/w)-(?!/w)', '', pub_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends = ['company','co','incorporated','inc','firm','press','group','publishers','publishing',\n",
    "                    'publications','pub','books','ltd','limited','society','house','associates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends_list = '|'.join([x.capitalize()+'\\.?(?!\\w)' for x in pub_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends = [x.capitalize() for x in pub_ends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "    for e, index in enumerate(indices):\n",
    "        \n",
    "        if (e==len(indices)-1):\n",
    "            end_index = -1\n",
    "        else:\n",
    "            end_index = indices[e+1][0]\n",
    "        \n",
    "        end_span = len(txt[indices[e][0]:end_index])   \n",
    "        get_match = re.finditer('[A-Z]\\w+[^A-Z]|[A-Z].[^A-Z]', txt[indices[e][0]:end_index])\n",
    "        matches = [(m.span(), m.group()) for m in get_match]\n",
    "        matches.reverse()\n",
    "        \n",
    "        for n, m in enumerate(matches):\n",
    "            if n<len(matches)-1:\n",
    "                if (m[0][1] != matches[n-1][0][0]):\n",
    "                    end_span = m[0][1]\n",
    "        \n",
    "        result = txt[indices[e][0]:(indices[e][0] + end_span - 1)]\n",
    "        \n",
    "        if len(result) > len(indices[e][1]):\n",
    "            names.append(txt[indices[e][0]:(indices[e][0] + end_span - 1)])\n",
    "            spans.append(indices[e][0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ split into tokens\n",
    "+ stop as soon \n",
    "+ stop as city names\n",
    "+ put word tokenizer in review obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_publishers = [\"Charles Scribner's Sons\",\"Scribner\",\"Macmillan\",\"Funk & Wagnalls\",\"McClure, Philips\",\"Houghton Mifflin\",\"G.P. Putnam's Sons\", \"G.P. Putnam\",\n",
    " \"Harper & Brothers\",\"Harper\",\"J.B. Lippincott\",\"J. B. Lippincott\", \"Doubleday, Page\",\"Doubleday\",\"D. Appleton\",\"Longmans, Green\",\n",
    " \"Longman\",\"Henry Holt\",\"Holt\",\"Adam & Charles Black\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "for filename, txt in zip([x.split('.')[0] for x in filenames], txts):\n",
    "    review_list.append(ReviewObj(filename, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = review_list[24].cleaned_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text = review_list[24].cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obscure_single_match(text, x, y):\n",
    "    text_list = list(text)\n",
    "    text_list[x:y] = list(len(text[x:y]) * '@')\n",
    "    return ''.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscure_single_match(temp_text, *(70,82))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in review_list[24].pub_names:\n",
    "    print(x.review_loc)\n",
    "    tbr = temp_text[x.review_loc[0]:x.review_loc[1]]\n",
    "    tr = len(tbr) * '@'\n",
    "    print(tbr)\n",
    "    print(tr)\n",
    "    temp_text.replace(tbr, tr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def __obscure_matches(self, name = 'ex'):\n",
    "    text_list = list(self.cleaned_text)\n",
    "    if name == 'pub':\n",
    "        for (x, y) in [pub.review_loc for pub in self.pub_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "        if name == 'person':\n",
    "            for (x, y) in [pers.review_loc for pers in self.person_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "        return ''.join(text_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dict = pickle.load(open('../data/city_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_part_of_pub(pub_part):\n",
    "    if (pub_part == 'and') or (pub_part =='&'):\n",
    "        return True\n",
    "    elif city_dict.lookup(pub_part.lower(), Verbosity.CLOSEST, max_edit_distance=1):\n",
    "        return False\n",
    "    else:\n",
    "        return pub_part.istitle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_part_of_pub('Egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubnames = []\n",
    "for e, tok in enumerate(toks):\n",
    "    if tok.replace(\",\",\"\").replace(\".\",\"\").replace('-',\"\") in pub_ends:\n",
    "        if is_part_of_pub(toks[e-1]):\n",
    "            pub_name = [tok]\n",
    "            pub_span = []\n",
    "            for pos in range(e-1, e-6, -1):\n",
    "                if toks[pos] == '.':\n",
    "                    break\n",
    "                elif not is_part_of_pub(toks[pos]):\n",
    "                    break\n",
    "                pub_name.append(toks[pos])\n",
    "                pub_span.append(pos)   \n",
    "            pubnames.append((pub_span[-1], e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_pubnames(pnlist):\n",
    "    cleaned = []\n",
    "    for e, (x, y) in enumerate(pnlist):\n",
    "        starts = [a for (a,b) in pnlist[e+1:]]\n",
    "        if x in starts:\n",
    "            pass\n",
    "        else:\n",
    "            cleaned.append(pnlist[e])\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "for e, (x, y) in enumerate(pubnames):\n",
    "    starts = [a for (a,b) in pubnames[e+1:]]\n",
    "    if x in starts:\n",
    "        pass\n",
    "    else:\n",
    "        cleaned.append(pubnames[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicate_pubnames(pubnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in pubnames:\n",
    "    newname = ' '.join(toks[x:y])\n",
    "    print(' '.join(toks[x:y]))\n",
    "    match = re.search(newname, review_list[0].cleaned_text)\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any([x.isalpha() for x in ['Cassel','&','Co.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publishers(review):\n",
    "    \"\"\"\n",
    "    Takes a ReviewObj. \n",
    "    Returns a list of potential publishers. Searches using pub_ends, capitalization, and associates.\n",
    "    \n",
    "    For reference:\n",
    "    -------------\n",
    "    pub_ends = ['co','company','inc','incorporated','firm','press','group', 'pub','publishers','publishing',\n",
    "                    'publications','books','ltd','limited','society','house','associates']\n",
    "                    \n",
    "    pub_associates = ['sons','son','brother','brothers']\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pubs = []\n",
    "    spans = []\n",
    "    \n",
    "    toks = review.cleaned_toks\n",
    "    txt = review.cleaned_text\n",
    "    \n",
    "    pubnames = []\n",
    "    \n",
    "    for e, tok in enumerate(toks):\n",
    "        if tok.replace(\",\",\"\").replace(\".\",\"\") in pub_ends:\n",
    "            if is_part_of_pub(toks[e-1]):\n",
    "                pub_name = []\n",
    "                pub_span = []\n",
    "                for pos in range(e-1, e-6, -1):\n",
    "                    if toks[pos] == '.':\n",
    "                        break\n",
    "                    if not is_part_of_pub(toks[pos]):\n",
    "                        break\n",
    "                    pub_name.append(toks[pos])\n",
    "                    pub_span.append(pos)\n",
    "                if any([x.isalpha() for x in [word for word in pub_name if word !='and']]) and any([len(x)>2 for x in [word for word in pub_name if word !='and']]):\n",
    "                    pubnames.append((pub_span[-1], e+1))\n",
    "    \n",
    "    if len(pubnames) > 0:\n",
    "        for (x, y) in pubnames:\n",
    "            newname = ' '.join(toks[x:y])\n",
    "            pubs.append(newname)\n",
    "            match = re.search(newname, txt)\n",
    "            spans.append(match.span())\n",
    "\n",
    "    pubs = [PubName(word) for word in pubs]\n",
    "    \n",
    "    for pub in pubs:\n",
    "        pub.review_id = review.review_id\n",
    "    \n",
    "    for e, pub in enumerate(pubs):\n",
    "        pub.review_id = review.review_id\n",
    "        pub.review_loc = spans[e]\n",
    "    \n",
    "    return pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "    rev = ReviewObj(filename, txt)\n",
    "    print(filename)\n",
    "    print(get_publishers(rev))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "    rev = ReviewObj(filename, txt)\n",
    "    print(filename)\n",
    "    if rev.person_names:\n",
    "        for x in rev.pub_names:\n",
    "            print(x)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Person Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = \"\"\"Doctor,Dr,Mr,Mrs,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Princess,Prince,Duke,Duchess,Baron,Father,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.rstrip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = '\\.?\\s(?=[A-Z])|'.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_not_following_title_or_initial(name):\n",
    "    name_parts = name.split()\n",
    "    cleaned_name = []\n",
    "    for part in name_parts:\n",
    "        if part[-1] in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~':\n",
    "            if (len(part)>2) and (part[:-1] not in titles):\n",
    "                cleaned_name.append(part[:-1])\n",
    "            else:\n",
    "                cleaned_name.append(part)\n",
    "        else:\n",
    "            cleaned_name.append(part)\n",
    "    return ' '.join(cleaned_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = remove_punct_not_following_title_or_initial(name)\n",
    "    cleaned_name = []\n",
    "    return ' '.join([word for word in name.split() if (word[0].isalpha())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCapitalizedWords(txt):\n",
    "    \"\"\"\n",
    "    Returns strings of capitalized words up 3 words long. \n",
    "    Removes words/phrases containing stopwords and words found later in the text lowercased.\n",
    "    \"\"\"\n",
    "    #listen idk why it won't just let me put in an optional repeat either\n",
    "    all_words = []\n",
    "    \n",
    "    #three words\n",
    "    all_words.extend([match for match in re.findall('[A-Z]\\S* [A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(remove_punct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(remove_punct(word).lower() not in txt) for word in match.split()])])\n",
    "    \n",
    "    #two words\n",
    "    two_words = [match for match in re.findall('[A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(remove_punct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(remove_punct(word).lower() not in txt) for word in match.split()])\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(two_words)\n",
    "    \n",
    "    #one word\n",
    "    one_words = [match for match in re.findall('[A-Z]\\S+', txt) if \n",
    "                      (remove_punct(match).lower() not in stopword_list) \n",
    "                      and (remove_punct(match).lower() not in txt)\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(one_words)\n",
    "    \n",
    "    return [word for word in [' '.join([removePunct(y) for y in x.split() if remove_punct(y) not in titles]) \n",
    "                      for x in all_words] if (len(word)>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidateNames(name_list):\n",
    "    \"\"\"\n",
    "    Takes list of AuthNames and returns list of lists, consolidating by likely identical authors.\n",
    "    \"\"\"\n",
    "    name_set = []\n",
    "    used_indices = []\n",
    "    last_names = sorted([name.last_name for name in name_list], key=len)\n",
    "    \n",
    "    for i, name in enumerate(last_names):\n",
    "        if i not in used_indices:\n",
    "            full_name = [x for x in name_list if x.last_name == name][0]\n",
    "            name_holder = [full_name]\n",
    "            for j, name2 in enumerate(last_names):\n",
    "                full_name2 = [x for x in name_list if x.last_name == name2][0]\n",
    "                if (i < (len(last_names) - 1)) and (i!=j):\n",
    "                    if (edit_distance(name, name2[:len(name)+1]) < 2) and (j not in used_indices):\n",
    "                        if (full_name.first_initial==full_name2.first_initial and full_name.middle_initial==full_name2.middle_initial or full_name.title==full_name2.title) or (full_name.first_initial==full_name2.first_initial or full_name.middle_initial==full_name2.middle_initial and full_name.title==full_name2.title):\n",
    "                            name_holder.append(full_name2)\n",
    "                            used_indices.append(j)\n",
    "            used_indices.append(i)\n",
    "            name_set.append(name_holder)\n",
    "    \n",
    "    return name_set                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obscure_matches(self, name = 'ex'):\n",
    "    text_list = list(self.cleaned_text)\n",
    "    if name == 'pub':\n",
    "        for (x, y) in [pub.review_loc for pub in self.pub_names]:\n",
    "            text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "    if name == 'person':\n",
    "        for (x, y) in [pers.review_loc for pers in self.person_names]:\n",
    "            text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "    return ''.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscure_matches(review_list[35], name = 'pub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list[0].no_pubs_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = review_list[0].cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in [x.review_loc for x in review_list[0].pub_names]:\n",
    "    print(text_list[x:y])\n",
    "    print(len(review_list[0].cleaned_text[x:y]) * '@')\n",
    "    text_list[x:y] = list(len(review_list[0].cleaned_text[x:y]) * '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_following_titles(review):\n",
    "    \"\"\"\n",
    "    Returns names following titles - specifically capitalized titles followed by capitalized names.\n",
    "    Names can be any number of words in length, and can include punctuation.\n",
    "    \n",
    "    \"\"\"\n",
    "    names = []\n",
    "    spans = []\n",
    "    \n",
    "    txt = review.cleaned_text\n",
    "\n",
    "    iterx = re.finditer(title_list, txt)\n",
    "    indices = [(m.start(), m.group()) for m in iterx]\n",
    "    \n",
    "    for e, index in enumerate(indices):\n",
    "        \n",
    "        if (e==len(indices)-1):\n",
    "            end_index = -1\n",
    "        else:\n",
    "            end_index = indices[e+1][0]\n",
    "        \n",
    "        end_span = len(txt[indices[e][0]:end_index])   \n",
    "        get_match = re.finditer('[A-Z]\\w+[^A-Z]|[A-Z].[^A-Z]', txt[indices[e][0]:end_index])\n",
    "        matches = [(m.span(), m.group()) for m in get_match]\n",
    "        matches.reverse()\n",
    "        \n",
    "        for n, m in enumerate(matches):\n",
    "            if n<len(matches)-1:\n",
    "                if (m[0][1] != matches[n-1][0][0]):\n",
    "                    end_span = m[0][1]\n",
    "        \n",
    "        result = txt[indices[e][0]:(indices[e][0] + end_span - 1)]\n",
    "        \n",
    "        if len(result) > len(indices[e][1]):\n",
    "            names.append(txt[indices[e][0]:(indices[e][0] + end_span - 1)])\n",
    "            spans.append(indices[e][0])\n",
    "        \n",
    "    names = [word.replace(\"'s\", \"\") for word in names]\n",
    "    names = [PersonName(clean_name(word)) for word in names]\n",
    "    \n",
    "    for e, name in enumerate(names):\n",
    "        name.review_id = review.review_id\n",
    "        name.review_loc = (spans[e], spans[e]+len(name))\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_names_following_titles(review_list[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReviewObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ReviewObj():\n",
    "    \n",
    "#     def __findnames(self):\n",
    "#         self.pub_names = get_publishers(self)\n",
    "#         self.person_names = get_names_following_titles(self)\n",
    "        \n",
    "#     def __init__(self, aps_id, txt):\n",
    "#         self.review_id = aps_id\n",
    "#         self.original_text = txt\n",
    "#         self.cleaned_text = preprocess_text(txt)\n",
    "        \n",
    "#         self.__findnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_ex = ReviewObj(136726613, txts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in review_ex.person_names:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "#     rev = ReviewObj(filename, txt)\n",
    "#     print(filename)\n",
    "#     if rev.person_names:\n",
    "#         for x in rev.person_names:\n",
    "#             print(x)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in review_ex.person_names:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy NLP object steal their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for txt, filename in zip(txts, [x.split('.')[0] for x in filenames]):\n",
    "#     print(filename)\n",
    "#     docnames = get_names_following_titles(txt, filename)\n",
    "#     for name in docnames:\n",
    "#         print(name, name.review_loc)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "Make each Person name aware of others and able to check for potential matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>C</th>\n",
       "      <th>55 day high</th>\n",
       "      <th>20 day low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 01:01:00</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 01:02:00</td>\n",
       "      <td>7158.31</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 01:03:00</td>\n",
       "      <td>7164.08</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 01:04:00</td>\n",
       "      <td>7157.01</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-01 01:05:00</td>\n",
       "      <td>7159.85</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2020-01-01 01:06:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-01 01:07:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 01:08:00</td>\n",
       "      <td>7145.28</td>\n",
       "      <td>7162.03</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2020-01-01 01:09:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7162.03</td>\n",
       "      <td>7147.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        C  55 day high  20 day low\n",
       "0  2020-01-01 01:01:00  7147.69      7163.32     7147.69\n",
       "1  2020-01-01 01:02:00  7158.31      7163.32     7147.69\n",
       "2  2020-01-01 01:03:00  7164.08      7163.32     7147.69\n",
       "3  2020-01-01 01:04:00  7157.01      7163.32     7147.69\n",
       "4  2020-01-01 01:05:00  7159.85      7163.32     7147.69\n",
       "5  2020-01-01 01:06:00  7161.29      7163.32     7147.69\n",
       "6  2020-01-01 01:07:00  7161.29      7163.32     7147.69\n",
       "7  2020-01-01 01:08:00  7145.28      7162.03     7147.69\n",
       "8  2020-01-01 01:09:00  7161.29      7162.03     7147.69"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>C</th>\n",
       "      <th>55 day high</th>\n",
       "      <th>20 day low</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 01:01:00</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 01:02:00</td>\n",
       "      <td>7158.31</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 01:03:00</td>\n",
       "      <td>7164.08</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-01 01:04:00</td>\n",
       "      <td>7157.01</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-01 01:05:00</td>\n",
       "      <td>7159.85</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2020-01-01 01:06:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2020-01-01 01:07:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7163.32</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 01:08:00</td>\n",
       "      <td>7145.28</td>\n",
       "      <td>7162.03</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2020-01-01 01:09:00</td>\n",
       "      <td>7161.29</td>\n",
       "      <td>7162.03</td>\n",
       "      <td>7147.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        C  55 day high  20 day low  result\n",
       "0  2020-01-01 01:01:00  7147.69      7163.32     7147.69       0\n",
       "1  2020-01-01 01:02:00  7158.31      7163.32     7147.69       0\n",
       "2  2020-01-01 01:03:00  7164.08      7163.32     7147.69       1\n",
       "3  2020-01-01 01:04:00  7157.01      7163.32     7147.69       1\n",
       "4  2020-01-01 01:05:00  7159.85      7163.32     7147.69       1\n",
       "5  2020-01-01 01:06:00  7161.29      7163.32     7147.69       1\n",
       "6  2020-01-01 01:07:00  7161.29      7163.32     7147.69       1\n",
       "7  2020-01-01 01:08:00  7145.28      7162.03     7147.69       0\n",
       "8  2020-01-01 01:09:00  7161.29      7162.03     7147.69       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame([\n",
    "    ['2020-01-01 01:01:00', 7147.69, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:02:00', 7158.31, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:03:00', 7164.08, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:04:00', 7157.01, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:05:00', 7159.85, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:06:00', 7161.29, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:07:00', 7161.29, 7163.32, 7147.69],\n",
    "    ['2020-01-01 01:08:00', 7145.28, 7162.03, 7147.69],\n",
    "    ['2020-01-01 01:09:00', 7161.29, 7162.03, 7147.69],\n",
    "], columns=['date', 'C', '55 day high', '20 day low'])\n",
    "\n",
    "new_col = []\n",
    "state = 0\n",
    "for row in df.iterrows():\n",
    "    if row[1]['C'] > row[1]['55 day high']:\n",
    "        state = 1\n",
    "    if row[1]['C'] < row[1]['20 day low']:\n",
    "        state = 0\n",
    "    new_col.append(state)\n",
    "\n",
    "df['result'] = new_col\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
