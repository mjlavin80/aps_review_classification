{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "- import various helpers, load data, select reviews by status and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "\n",
    "from application.review_obj_class import ReviewObj\n",
    "\n",
    "from application.text_preprocessing import preprocess_text\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "import database.models as models\n",
    "\n",
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "\n",
    "len(aps_details_single)\n",
    "\n",
    "titles = [i.reviewed_book_title for i in aps_details_single if i.reviewed_book_title != '' and i.reviewed_book_title is not None]\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_parsed = [ReviewObj(i.record_id, i.full_text) for i in aps_details_single if i.reviewed_book_title != '' and i.reviewed_book_title is not None]\n",
    "#reviews_parsed[0].cleaned_text\n",
    "#reviews_parsed[0].cleaned_toks[:10]\n",
    "len(reviews_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'bone', 'of', 'contention', 'is', 'a', 'stroke', 'of', 'wit', 'it', 'does', 'however', 'rightly', 'describe', 'the']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzysearch import find_near_matches\n",
    "from nltk import word_tokenize\n",
    "\n",
    "all_matches = {}\n",
    "befores = []\n",
    "afters = []\n",
    "for e,i in enumerate(reviews_parsed):\n",
    "    t = titles[e]\n",
    "    #base fuzziness on length of pubname\n",
    "    if len(t) < 5:\n",
    "        fuzz=0\n",
    "    elif len(t) > 5 and len(t) < 10:\n",
    "        fuzz=1\n",
    "    elif len(t) > 9 and len(t) < 20:\n",
    "        fuzz=2\n",
    "    else:\n",
    "        fuzz=3\n",
    "    matches = find_near_matches(t, i.cleaned_text, max_l_dist=fuzz)\n",
    "    if len(matches) > 0:\n",
    "        match_strings = [i.cleaned_text[m.start:m.end] for m in matches]\n",
    "        last = 0\n",
    "        next_m = 1\n",
    "        \n",
    "        for x, m in enumerate(matches):\n",
    "            before = i.cleaned_text[last:m.start]\n",
    "            if next_m >= len(matches):\n",
    "                after = i.cleaned_text[m.end:]\n",
    "            else:\n",
    "                after = i.cleaned_text[m.end: matches[next_m].start]\n",
    "            \n",
    "            \n",
    "            last = m.end+1\n",
    "            next_m = x+2\n",
    "            \n",
    "            #lowercase and remove punctuation tokens\n",
    "            before_tokens = [c.lower() for c in word_tokenize(before) if c.isalpha()]\n",
    "            after_tokens = [c.lower() for c in word_tokenize(after) if c.isalpha()]\n",
    "            befores.append(before_tokens)\n",
    "            afters.append(after_tokens)        \n",
    "    \n",
    "        #for i in match_strings:\n",
    "            #try:\n",
    "                #all_matches[t][i] +=1\n",
    "            #except:\n",
    "                #all_matches[t] = {}\n",
    "                #all_matches[t][i] = 1\n",
    "befores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'the', 'past', 'and', 'vividly', 'writes', 'in', 'a', 'phrase', 'her', 'political', 'history', 'until', 'the', 'triumph', 'of', 'the', 'union', 'armies', 'and', 'the', 'close', 'of', 'the', 'civil', 'war']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of_the', 6), ('volume_of', 5), ('edition_of', 3), ('life_of', 3), ('chapter_of', 3), ('law_of', 3), ('egypt_explor', 3), ('the_h', 3), ('story_of', 3), ('the_title', 2), ('volume_called', 2), ('this_of', 2), ('literary_history', 2), ('of_which', 2), ('original_character', 2), ('is_not', 2), ('in_which', 2), ('first_novel', 2), ('latest_novel', 2), ('study_of', 2), ('her_godfa', 2), ('the_m', 2), ('the_i', 2), ('the_egypti', 2), ('of_r', 2), ('at_le', 2), ('the_v', 2), ('seven_li', 2), ('such_d', 2), ('give_us', 2)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "bigrams = []\n",
    "for tokens in befores:\n",
    "    if len(tokens) > 3:\n",
    "        bigrams.append(\"_\".join(tokens[-2:]))\n",
    "Counter(bigrams).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first chapter of\n",
    "# chapter of\n",
    "# his latest\n",
    "# of the \n",
    "# volume of\n",
    "# edition of\n",
    "# volume called \n",
    "# first novel \n",
    "# study of\n",
    "# of which \n",
    "# latest novel\n",
    "# the author of \n",
    "# the manner in which \n",
    "# with the title \n",
    "# titled?\n",
    "# book \n",
    "# novel \n",
    "# entitled\n",
    "# is, it is, book is, what is\n",
    "# life of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is_a', 16), ('of_the', 9), ('edited_by', 8), ('by_the', 8), ('in_the', 7), ('from_the', 5), ('by_george', 5), ('as_a', 4), ('it_is', 4), ('and_the', 4), ('by_john', 4), ('by_charles', 4), ('is_an', 4), ('by_edward', 3), ('a_study', 3), ('at_the', 3), ('is_the', 3), ('by_edgar', 3), ('in_which', 3), ('n_by', 3)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = []\n",
    "for tokens in afters:\n",
    "    if len(tokens) > 3:\n",
    "        bigrams.append(\"_\".join(tokens[0:2]))\n",
    "Counter(bigrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"[title] is a\", \"[title] is an\", \"[title] by [author]\", \n",
    "#\"[title] in the\", \"[title] from the\", \"[title] is the title\"\n",
    "#[title] is a novel\", [title] is a story\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
