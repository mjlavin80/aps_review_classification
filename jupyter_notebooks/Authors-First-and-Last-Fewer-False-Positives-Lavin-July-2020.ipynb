{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "- import various helpers, load data, select reviews by status and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "\n",
    "from application.review_obj_class import ReviewObj\n",
    "\n",
    "from application.text_preprocessing import preprocess_text\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.corpus import stopwords\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import application.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "\n",
    "len(aps_details_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_parsed = [ReviewObj(i.record_id, i.full_text) for i in aps_details_single if i.reviewed_author_name !='' and i.reviewed_author_name is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [i.reviewed_author_name for i in aps_details_single if i.reviewed_author_name !='' and i.reviewed_author_name is not None]\n",
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_author_candidates(review):\n",
    "    titles = \"\"\"Doctor,Dr,Mr,Mrs,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Princess,Prince,Duke,Duchess,Baron,Father,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\"\"\"\n",
    "    titles = titles.rstrip().split(',')\n",
    "    title_list = '\\.?\\s(?=[A-Z])|'.join(titles) + '\\.?\\s(?=[A-Z])'\n",
    "\n",
    "    text = review.no_pubs_text.split()\n",
    "\n",
    "    full_names = {}\n",
    "\n",
    "    for e,i in enumerate(text):\n",
    "        maybe_title = \"\".join([z for z in i if z.isalpha()])\n",
    "        if len(maybe_title) > 0:\n",
    "            if maybe_title[0].isupper() and maybe_title in titles:\n",
    "                \n",
    "                surname = []\n",
    "                for p in [e+1, e+2, e+3, e+4, e+5]:\n",
    "                    try:\n",
    "                        if text[p] == \".\" and len(text[p-1]) > 1:\n",
    "                            break\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    try:\n",
    "                        if text[p][0].isupper():\n",
    "                            if text[p].lower() not in stopwords.words('english'):\n",
    "                                surname.append(text[p])\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        if text[p][-1] == \".\" and len(text[p]) > 2:\n",
    "                            break\n",
    "                    except:\n",
    "                        pass\n",
    "                if len(surname) > 0:\n",
    "                    surname = \" \".join(surname).replace(\"'s\", \"\")\n",
    "                    surname_cleaned = []\n",
    "                    for s in surname:\n",
    "                        if s not in '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~':\n",
    "                            surname_cleaned.append(s)\n",
    "                    surname_cleaned = \"\".join(surname_cleaned)\n",
    "                    try:\n",
    "                        check = full_names[surname]\n",
    "                    except:\n",
    "                        full_names[surname] = {}\n",
    "                    try:\n",
    "                        full_names[surname]['title'].append(maybe_title)\n",
    "                    except:\n",
    "                        full_names[surname]['title'] = [maybe_title,]\n",
    "                    try:\n",
    "                        full_names[surname]['surname_cleaned'].append(surname_cleaned)\n",
    "                    except:\n",
    "                        full_names[surname]['surname_cleaned'] = [surname_cleaned,]\n",
    "\n",
    "    for surname in full_names.keys():\n",
    "        s = surname.split()\n",
    "        for e, i in enumerate(text):\n",
    "            if text[e:e+len(s)] == s:\n",
    "                forename = \"\".join([x for x in text[e-1] if x.isalpha()])\n",
    "                if forename.istitle() and forename not in titles:\n",
    "                    try:\n",
    "                        full_names[surname]['forename'].append(forename)\n",
    "                    except:\n",
    "                        full_names[surname]['forename'] = [forename,]\n",
    "            try:\n",
    "                forenames = full_names[surname]['forename']\n",
    "            except:\n",
    "                full_names[surname]['forename'] = []\n",
    "    \n",
    "    for name in full_names.keys():\n",
    "        for i in full_names[name]['forename']:\n",
    "            try: \n",
    "                full_names[name]['full_name'].append(i + \" \" + name)\n",
    "            except:\n",
    "                full_names[name]['full_name'] = [i + \" \" + name,]\n",
    "        try:\n",
    "            full = full_names[surname]['full_name']\n",
    "        except:\n",
    "            full_names[name]['full_name'] = []\n",
    "    full_name_candidates = {}\n",
    "\n",
    "    for n in full_names.keys():\n",
    "        for f in full_names[n]['full_name']:\n",
    "            try:\n",
    "                full_name_candidates[f] += 1\n",
    "            except:\n",
    "                full_name_candidates[f] = 1\n",
    "\n",
    "    # add title and surnames\n",
    "    for n,o in full_names.items():\n",
    "        for i in o['surname_cleaned']:\n",
    "            # check if surname in a full name\n",
    "            name_part = False\n",
    "            for full in full_name_candidates.keys():\n",
    "                if i in full:\n",
    "                    name_part = True\n",
    "            if not name_part:\n",
    "                try: \n",
    "                    full_name_candidates[i] += 1\n",
    "                except:\n",
    "                    full_name_candidates[i] = 1\n",
    "    return full_name_candidates\n",
    "\n",
    "# Screen out names that are extremely common single words like 'there'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_author_candidates(reviews_parsed[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_parsed[1].cleaned_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Person Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_authors = list(set(authors))\n",
    "len(known_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_authors = list(set([z for i in known_authors for z in i.split(\";\")]))\n",
    "len(known_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "def match_known_authors(text, k_a):\n",
    "    all_matches = {}\n",
    "    for can in k_a:\n",
    "        \n",
    "        #base fuzziness on length of author name\n",
    "        if len(can) < 10:\n",
    "            fuzz=0\n",
    "        elif len(can) > 9 and len(can) < 20:\n",
    "            fuzz=1\n",
    "        else:\n",
    "            fuzz=3\n",
    "        matches = find_near_matches(can, text, max_l_dist=fuzz)\n",
    "        if len(matches) > 0:\n",
    "            match_strings = [text[m.start:m.end] for m in matches]\n",
    "            for i in match_strings:\n",
    "                try:\n",
    "                    all_matches[can].append(i)\n",
    "                except:\n",
    "                    all_matches[can] = [i,]\n",
    "        for k,v in all_matches.items():\n",
    "            if len(v) == 1 and k == v[0]:  \n",
    "                return (\"found\", [k,])\n",
    "            \n",
    "    result = list(all_matches.keys())\n",
    "    if len(result) > 0:\n",
    "        return (\"found\", result)\n",
    "    else:\n",
    "        return (\"not found\", result)\n",
    "\n",
    "def match_surname(text, k_a):\n",
    "    all_matches = {}\n",
    "    for can in k_a:\n",
    "        # get last item in name string\n",
    "        surname = can.split()[-1]\n",
    "        \n",
    "        #base fuzziness on length of author name\n",
    "        if len(surname) < 10:\n",
    "            fuzz=0\n",
    "        elif len(surname) > 9 and len(surname) < 20:\n",
    "            fuzz=1\n",
    "        else:\n",
    "            fuzz=3\n",
    "        matches = find_near_matches(surname, text, max_l_dist=fuzz)\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            match_strings = [text[m.start:m.end] for m in matches]\n",
    "            for i in match_strings:\n",
    "                try:\n",
    "                    all_matches[can].append(i)\n",
    "                except:\n",
    "                    all_matches[can] = [i,]\n",
    "        for k,v in all_matches.items():\n",
    "            if len(v) == 1 and k == v[0]:  \n",
    "                return (\"found\", [k,])\n",
    "    result = list(all_matches.keys())\n",
    "    \n",
    "    if len(result) > 0:\n",
    "        return (\"found\", result)\n",
    "    else:\n",
    "        return (\"not found\", result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = make_author_candidates(reviews_parsed[1])\n",
    "for name, score in candidates.items():\n",
    "    print(name, score, match_known_authors(name, known_authors))\n",
    "    #print(name, score, match_surname(name, known_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_author_matches = {}\n",
    "\n",
    "# run on all reviews, return matches, novel, or no match\n",
    "for review in reviews_parsed:\n",
    "    \n",
    "    results = {}\n",
    "    #names = list(set(review.person_names))\n",
    "    candidates = make_author_candidates(review)\n",
    "    \n",
    "    for i, score in candidates.items():\n",
    "        # function to fuzzy match known authors\n",
    "        result, author_candidates = match_known_authors(i, known_authors)\n",
    "        if len(author_candidates) == 0:\n",
    "            result, author_surname_candidates = match_surname(i, known_authors)\n",
    "            if len(author_surname_candidates) > 0:\n",
    "                for z in author_surname_candidates:\n",
    "                    if len(z.strip()) > 2:\n",
    "                        try:\n",
    "                            results[i].append(z)\n",
    "                        except:\n",
    "                            results[i] = [z,]\n",
    "        else:\n",
    "            for z in author_candidates:\n",
    "                if len(z.strip()) > 2:\n",
    "                    try:\n",
    "                        results[i].append(z)\n",
    "                    except:\n",
    "                        results[i] = [z,]\n",
    "    \n",
    "    if len(results.keys()) == 0:        \n",
    "        result = \"not found\"\n",
    "\n",
    "    if len(review.person_names) == 0:        \n",
    "        result = \"not found\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        all_author_matches[\"type\"].append(result) \n",
    "    except:\n",
    "        all_author_matches[\"type\"] = [result,]\n",
    "        \n",
    "    try:\n",
    "        all_author_matches[\"results\"].append(results)\n",
    "    except:\n",
    "        all_author_matches[\"results\"] = [results,]\n",
    "    try:\n",
    "        all_author_matches[\"match_number\"].append(len(results.keys()))\n",
    "    except:\n",
    "        all_author_matches[\"match_number\"] = [len(results.keys()),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_author_matches[\"results\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build viaf store, add columns for comparison\n",
    "author_tuples = [(i.reviewed_author_name, i.reviewed_author_viaf_match) for i in aps_details_single if i.reviewed_author_name is not None and i.reviewed_author_name !='']\n",
    "viaf_store = {}\n",
    "count = 0\n",
    "for f,g in author_tuples:\n",
    "    i = f.split(\";\")\n",
    "    uris = g.split(\";\")\n",
    "    i = f.split(\";\")\n",
    "    uris = g.split(\";\")\n",
    "    tail = []\n",
    "    if len(i) > len(uris):\n",
    "        for m in range(len(i) - len(uris)):\n",
    "            tail.append('not available')\n",
    "        uris = uris+tail\n",
    "    if len(uris) > len(i):\n",
    "        uris = uris[:4]\n",
    "        i = i[:4]\n",
    "        \n",
    "    for e, j in enumerate(uris):\n",
    "        if j == '' or j.lower() == \"not available\":\n",
    "            try: \n",
    "                is_in = viaf_store[i[e]]\n",
    "            except:\n",
    "                viaf_store[i[e]] = [count,]\n",
    "                count +=1\n",
    "        else:\n",
    "            try:\n",
    "                if j not in viaf_store[i[e]]:\n",
    "                    viaf_store[i[e]].append(j)\n",
    "            except:\n",
    "                viaf_store[i[e]] = [j,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "top_candidates = []\n",
    "for r in all_author_matches['results']:\n",
    "    top = {}\n",
    "    for a,b in r.items():\n",
    "        for c in b: \n",
    "            score = edit_distance(a,c)\n",
    "            try:\n",
    "                top[a][c] = score\n",
    "            except:\n",
    "                top[a] = {}\n",
    "                top[a][c] = score\n",
    "        #should be room to improve this\n",
    "        \n",
    "    best = []\n",
    "    for i,j in top.items():\n",
    "        lowest = \"\"\n",
    "        score = 100\n",
    "        for c,s in j.items():\n",
    "            if s < score:\n",
    "                lowest = c\n",
    "                score = s\n",
    "        best.append(lowest)\n",
    "    best.sort()\n",
    "    best = list(set(best))\n",
    "    top_candidates.append(\";\".join(best))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_author_matches)\n",
    "df['recorded_authors'] = authors\n",
    "df['top_candidates'] = top_candidates\n",
    "#df['recorded_viaf'] = recorded_viaf\n",
    "#df['top_result_viaf'] = top_result_viaf\n",
    "df = df.drop(['results'], axis=1)\n",
    "len(df.loc[(df['match_number'] == 1) & (df['recorded_authors'] == df['top_candidates'])])/len(df.loc[(df['match_number'] == 1)])\n",
    "#78% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[(df['match_number'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_authors = []\n",
    "for row in df.iterrows():\n",
    "    true_authors.extend(row[1]['recorded_authors'].split(\";\"))\n",
    "len(true_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_count = []\n",
    "missed_author_count = []\n",
    "matched_correctly_count = []\n",
    "perfect_match_count = []\n",
    "\n",
    "for row in df.iterrows():\n",
    "    candidate_list = [i.strip() for i in row[1]['top_candidates'].split(\";\") if i !='']\n",
    "    target_list = [i.strip() for i in row[1]['recorded_authors'].split(\";\") if i !='']\n",
    "    if len(candidate_list) > 1:\n",
    "        # number of matches and number of false positives\n",
    "        fp = 0\n",
    "        matches = 0\n",
    "        for name in candidate_list:\n",
    "            if name not in target_list:\n",
    "                fp += 1\n",
    "\n",
    "            else:\n",
    "                matches += 1\n",
    "        false_positives_count.append(fp)\n",
    "        matched_correctly_count.append(matches)\n",
    "\n",
    "        # number of missed authors\n",
    "        fn = 0\n",
    "        for name in target_list:\n",
    "            if name not in candidate_list:\n",
    "                fn +=1\n",
    "        missed_author_count.append(fn)\n",
    "\n",
    "        # perfect match?\n",
    "        if fn == 0 and fp == 0:\n",
    "            perfect = True\n",
    "        else:\n",
    "            perfect = False\n",
    "\n",
    "        perfect_match_count.append(perfect)\n",
    "sum(false_positives_count), sum(missed_author_count), sum(matched_correctly_count)\n",
    "#(149, 35, 149)\n",
    "# including single match (188, 84, 309)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in perfect_match_count if i == True])/len(perfect_match_count)\n",
    "#0.3157894736842105\n",
    "#0.3157894736842105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try all of this with reviews_parsed.no_pubs_text\n",
    "len(perfect_match_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
