{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/english_words.txt\") as f:\n",
    "    english = f.read() \n",
    "    f.close()\n",
    "\n",
    "ENGLISH = {i:True for i in english.split(\"\\n\")}\n",
    "\n",
    "def is_english(word):\n",
    "    try:\n",
    "        ENGLISH[word]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "correction_rules = {}\n",
    "with open('../data/CorrectionRules.txt') as f:\n",
    "    filelines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "for line in filelines:\n",
    "    line = line.rstrip()\n",
    "    fields = line.split(\"\\t\")\n",
    "    correction_rules[fields[0]] = fields[1]\n",
    "\n",
    "hyphen_rules = {}\n",
    "\n",
    "with open('../data/HyphenRules.txt') as f:\n",
    "    filelines = f.readlines()\n",
    "    filelines.reverse()\n",
    "    # Doing this so that unhyphenated forms get read before hyphenated ones.\n",
    "    f.close()\n",
    "\n",
    "for line in filelines:\n",
    "    line = line.rstrip()\n",
    "    fields = line.split(\"\\t\")\n",
    "    Word = fields[0].rstrip()\n",
    "    Corr = fields[1].rstrip()\n",
    "    hyphen_rules[Word] = Corr\n",
    "    if \" \" in Corr:\n",
    "        StripWord = Word.replace(\"-\", \"\")\n",
    "        hyphen_rules[StripWord] = Corr\n",
    "        # That's so that we split \"tigermoth\" as well as \"tiger-moth\" into \"tiger moth.\"\n",
    "            \n",
    "    if \"-\" in Word:\n",
    "        StripWord = Word.replace(\"-\", \"\")\n",
    "        StripCorr = Corr.replace(\" \", \"\")\n",
    "        StripCorr = StripCorr.replace(\"-\", \"\")\n",
    "        if StripWord != StripCorr and StripWord not in hyphen_rules:\n",
    "            hyphen_rules[StripWord] = Corr\n",
    "            \n",
    "        ## The purpose of this is a bit obscure to me. It may be deletable.\n",
    "\n",
    "fuse_rules = {}\n",
    "with open('../data/FusingRules.txt') as f:\n",
    "    filelines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "for Line in filelines:\n",
    "    Line = Line.rstrip()\n",
    "    LineParts = Line.split(\"\\t\")\n",
    "    Word = LineParts[0].rstrip()\n",
    "    Word = tuple(Word.split(' '))\n",
    "    Corr = LineParts[1].rstrip()\n",
    "    fuse_rules[Word] = Corr\n",
    "\n",
    "syncope_rules = {}\n",
    "with open('../data/SyncopeRules.txt') as f:\n",
    "    filelines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "for line in filelines:\n",
    "    line = line.rstrip()\n",
    "    fields = line.split(\"\\t\")\n",
    "    syncope_rules[fields[0]] = fields[1]\n",
    "\n",
    "variant_rules = {}\n",
    "with open('../data/VariantSpellings.txt') as f:\n",
    "    filelines = f.readlines()\n",
    "    f.close()\n",
    "        \n",
    "for line in filelines:\n",
    "    line = line.rstrip()\n",
    "    fields = line.split(\"\\t\")\n",
    "    variant_rules[fields[0]] = fields[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_by_dict(tokens, rulestore):\n",
    "    \"\"\"A generalized function to apply substitution rules to a list of tokens\"\"\"\n",
    "    output = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            new = rulestore[token]\n",
    "            output.append(new)\n",
    "        except:\n",
    "            output.append(token)\n",
    "    return output\n",
    "\n",
    "def hyphen_split(tokens):\n",
    "    tokens_hyphen_split = []\n",
    "    for i in tokens:\n",
    "        if '-' in i:\n",
    "            term_list = i.split('-')\n",
    "            if is_english(\"\".join(term_list)):\n",
    "                tokens_hyphen_split.append(''.join(term_list))\n",
    "            else:    \n",
    "                e = True\n",
    "                # test if all words are in the English dictionary\n",
    "                for i in term_list:\n",
    "                    if not is_english(i):\n",
    "                        e = False\n",
    "                        break\n",
    "                if e == True:\n",
    "                    tokens_hyphen_split.extend(term_list)\n",
    "                else:\n",
    "                    tokens_hyphen_split.append(''.join(term_list))\n",
    "        else:\n",
    "            tokens_hyphen_split.append(i)\n",
    "    return tokens_hyphen_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move to tests folder\n",
    "test = ['tbis', 'is','fome', 'dirty','ocr', 'tbat', 'i', 'want', 'to', 'test', 'abso-lutely', 'noth-ing', 'I', 'can', 'do', 'topsy-turvy', 'bitter-sweet']\n",
    "\n",
    "for i in [correction_rules, hyphen_rules, fuse_rules, syncope_rules, variant_rules]:\n",
    "    test = substitute_by_dict(test, i)\n",
    "test = hyphen_split(test)\n",
    "test == ['this','is','some','dirty','ocr','that','i','want','to','test','absolutely','nothing','i','can','do','topsyturvy','bittersweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "\n",
    "from application.review_obj_class import ReviewObj\n",
    "\n",
    "from application.text_preprocessing import preprocess_text\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "import database.models as models\n",
    "\n",
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "\n",
    "len(aps_details_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Missouri', 'The Confessions of Lord Byron', 'Carnival', 'Photographic Illustrations of Cutaneous Syphilis', 'Life and Letters of Dante Gabriel Rossetti']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [i.reviewed_book_title for i in aps_details_single]\n",
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Missouri', ':', 'A', 'Bone', 'of', 'Contention', \"'\", 'WE', 'aware', 'that']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_parsed = [ReviewObj(i.record_id, i.full_text) for i in aps_details_single]\n",
    "#reviews_parsed[0].cleaned_text\n",
    "reviews_parsed[0].cleaned_toks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_function_tail(sequence):\n",
    "    if sequence[-1].lower() in stopwords.words('english'):\n",
    "        sequence.pop()\n",
    "        return remove_function_tail(sequence)\n",
    "    else:\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_candidates_tidy = []\n",
    "for one_review in reviews_parsed:\n",
    "    title_candidates = [list(),]\n",
    "    for token in one_review.cleaned_toks:\n",
    "        if token.istitle() or token in stopwords.words('english') or token in string.punctuation:\n",
    "            if len(title_candidates[-1]) > 0:\n",
    "                if token not in string.punctuation:\n",
    "                    title_candidates[-1].append(token)\n",
    "            else:\n",
    "                if token.istitle():\n",
    "                    title_candidates[-1].append(token)\n",
    "        else:\n",
    "            if len(title_candidates[-1]) > 0:\n",
    "                title_candidates.append(list())\n",
    "    \n",
    "    candidates_tidy = []\n",
    "    for sequence in title_candidates:\n",
    "        # rule out if all function words\n",
    "        all_function = True\n",
    "        for word in sequence:\n",
    "            if word.lower() not in stopwords.words('english'):\n",
    "                all_function = False\n",
    "                break\n",
    "        if all_function == False:\n",
    "            #remove function word tails recursively\n",
    "            sequence = remove_function_tail(sequence)\n",
    "            candidates_tidy.append(sequence)\n",
    "    all_candidates_tidy.append(candidates_tidy ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "# loop all_candidates_tidy\n",
    "for e,t in enumerate(all_candidates_tidy):\n",
    "    # true label is titles[e]\n",
    "    # get headline text\n",
    "    block_one = aps_details_single[e].record_title\n",
    "    block_one_tokens = word_tokenize(block_one)\n",
    "    \n",
    "    \n",
    "    for ruleset in [correction_rules, hyphen_rules, fuse_rules, syncope_rules, variant_rules]:\n",
    "        block_one_tokens = substitute_by_dict(block_one_tokens, ruleset)\n",
    "        \n",
    "    block_one = \" \".join(block_one_tokens)\n",
    "    \n",
    "    text_blocks = []\n",
    "    for i in t:\n",
    "        for rule in [correction_rules, hyphen_rules, fuse_rules, syncope_rules, variant_rules]:\n",
    "            i = substitute_by_dict(i, rule)\n",
    "        text_blocks.extend(i)\n",
    "    \n",
    "    text_merged = [block_one + \" \" + \" \".join(text_blocks),]    \n",
    "    \n",
    "    title_tokens = [word_tokenize(i) for i in titles]\n",
    "    titles_normed = []\n",
    "    for i in title_tokens:\n",
    "        for rule in [correction_rules, hyphen_rules, fuse_rules, syncope_rules, variant_rules]:\n",
    "            i = substitute_by_dict(i, rule)\n",
    "        titles_normed.append(\" \".join(i))\n",
    "        \n",
    "    # this title is comparison_set[-1]\n",
    "    comparison_set = titles_normed + text_merged\n",
    "\n",
    "    # compare \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(comparison_set)\n",
    "    vectors = X.toarray()\n",
    "    # loop all, get similarity, last one is always 1.0\n",
    "    scores = []\n",
    "    for v in vectors:\n",
    "        score = cosine_similarity([v], [vectors[-1]])\n",
    "        scores.append(score)\n",
    "    all_scores.append(scores)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often is the right answer the top answer? how often is the correct match in the top 5?\n",
    "output = []\n",
    "for e, score_grid in enumerate(all_scores):\n",
    "    df = pd.DataFrame()\n",
    "    df['score'] = [i[0][0] for i in score_grid][:-1]\n",
    "    df['title'] = titles\n",
    "    match = []\n",
    "    for i in range(len(titles)):\n",
    "        if e == i:\n",
    "            match.append('yes')\n",
    "        else:\n",
    "            match.append('no')\n",
    "    df['match'] = match\n",
    "    output.append(df.sort_values(by=\"score\", ascending=False).reset_index(drop=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_match = []\n",
    "top_five = []\n",
    "top_ten = []\n",
    "top_25 = []\n",
    "for i in output:\n",
    "    df_five = i.iloc[:5]\n",
    "    df_ten = i.iloc[:10]\n",
    "    df_25 = i.iloc[:25]\n",
    "    top_match.append(i.iloc[0]['match'] == 'yes')\n",
    "    top_five.append(len(df_five.loc[df_five['match'] == 'yes']) > 0)\n",
    "    top_ten.append(len(df_ten.loc[df_ten['match'] == 'yes']) > 0)\n",
    "    top_25.append(len(df_25.loc[df_25['match'] == 'yes']) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7308377896613191"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50% correct without headline; 55.25% with; 55.43 with correction rules\n",
    "len([i for i in top_match if i])/len(top_match)\n",
    "# 62%; 65.59%; 65.59\n",
    "len([i for i in top_five if i])/len(top_five)\n",
    "# 65%; 68.98; 69.16\n",
    "len([i for i in top_ten if i])/len(top_ten)\n",
    "#69%; 73.44; 73.08\n",
    "len([i for i in top_25 if i])/len(top_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>original_index</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636107</td>\n",
       "      <td>The Confessions of Lord Byron</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.373718</td>\n",
       "      <td>Carnival</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>Life and Letters of Dante Gabriel Rossetti</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305888</td>\n",
       "      <td>Master of Ballantrae</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "      <td>553</td>\n",
       "      <td>0.345285</td>\n",
       "      <td>Une Nuit au Luxembourg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "      <td>554</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>Chapters on Greek Metric</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>0.349927</td>\n",
       "      <td>Moses Brown, Captain, U.S.N.</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "      <td>559</td>\n",
       "      <td>0.583383</td>\n",
       "      <td>Creative Chemistry</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>0.594089</td>\n",
       "      <td>Avon's Harvest</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank  original_index     score  \\\n",
       "0       0               0  0.674200   \n",
       "1       0               1  0.636107   \n",
       "2       0               2  0.373718   \n",
       "4       0               4  0.678571   \n",
       "5       0               5  0.305888   \n",
       "..    ...             ...       ...   \n",
       "553     0             553  0.345285   \n",
       "554     0             554  0.187500   \n",
       "557     0             557  0.349927   \n",
       "559     0             559  0.583383   \n",
       "560     0             560  0.594089   \n",
       "\n",
       "                                          title match  \n",
       "0                                      Missouri   yes  \n",
       "1                 The Confessions of Lord Byron   yes  \n",
       "2                                      Carnival   yes  \n",
       "4    Life and Letters of Dante Gabriel Rossetti   yes  \n",
       "5                          Master of Ballantrae   yes  \n",
       "..                                          ...   ...  \n",
       "553                      Une Nuit au Luxembourg   yes  \n",
       "554                    Chapters on Greek Metric   yes  \n",
       "557                Moses Brown, Captain, U.S.N.   yes  \n",
       "559                          Creative Chemistry   yes  \n",
       "560                              Avon's Harvest   yes  \n",
       "\n",
       "[311 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_audit = []\n",
    "for i in output:\n",
    "    df = i.loc[i['match'] == 'yes']\n",
    "    results_audit.append(df)\n",
    "# results_audit[10]\n",
    "# this title was 214th out of len(titles)\n",
    "df = pd.concat(results_audit).reset_index(drop=False)\n",
    "df = df.rename(columns={\"index\": \"original_index\", \"level_0\": \"rank\"})\n",
    "df.loc[df['rank'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This kind of normalization doesn't seem to improve accuracy in a meaningful way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py365",
   "language": "python",
   "name": "py365"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
