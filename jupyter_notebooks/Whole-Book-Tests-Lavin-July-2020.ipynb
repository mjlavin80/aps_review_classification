{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from database import *\n",
    "import database.models as models\n",
    "\n",
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "aps_details_w_title = [i for i in aps_details_single if i.reviewed_book_title != '' and i.reviewed_book_title is not None]\n",
    "publishers = [i.reviewed_book_publisher for i in aps_details_single if i.reviewed_book_publisher !='']\n",
    "known_publishers = list(set(publishers))\n",
    "len(aps_details_w_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.review import ReviewObject\n",
    "from application.name_obj_classes import remove_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'american commonwealths boston itoughto. sftfltn co.': 1.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_instances = []\n",
    "for r in aps_details_single:\n",
    "    one_review = ReviewObject(title=r.reviewed_book_title, known_publishers=known_publishers, **r.__dict__)\n",
    "    review_instances.append(one_review)\n",
    "review_instances[0].top_publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzysearch import find_near_matches\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from nltk.metrics import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_lists = []\n",
    "for e,i in enumerate(aps_details_single):\n",
    "    this_record = {}\n",
    "    for z in [\"reviewed_book_title\", \"reviewed_author_name\", \"reviewed_book_publisher\", \\\n",
    "              \"reviewed_author_viaf_match\", \"reviewed_book_publisher_viaf_match\", \"year\"]:\n",
    "        this_record[z] = getattr(i, z)\n",
    "        \n",
    "        if z in [\"reviewed_book_title\", \"reviewed_author_name\", \"reviewed_book_publisher\"]:\n",
    "            tokens = word_tokenize(this_record[z].lower())\n",
    "            tokens = [j.replace(\"&\", \"and\") for j in tokens]\n",
    "            tokens = [j for j in tokens if j not in string.punctuation]\n",
    "            this_record[z+\"_tokens\"] = tokens\n",
    "    this_record[\"record_tokens\"] = this_record[\"reviewed_book_title_tokens\"] + this_record[\"reviewed_author_name_tokens\"] + this_record[\"reviewed_book_publisher_tokens\"] \n",
    "    ground_truth_lists.append(this_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['missouri', 'lucien', 'carr', 'houghton', 'mifflin', 'and', 'company']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_lists[0]['record_tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_candidates_and_labels(c, l):\n",
    "    \"\"\" compares and aligns two token lists \"\"\"\n",
    "    # check for whole object and sub-token matches for equal number of tokens... such as surname and publisher name (distance of best alignment)\n",
    "    if len(c) > len(l):\n",
    "        longer = c\n",
    "        shorter = l\n",
    "    else: \n",
    "        longer = l\n",
    "        shorter = c\n",
    "    best_distance = sum([len(i) for i in longer])\n",
    "    best_start = 0\n",
    "    \n",
    "    for en, comp in enumerate(longer):\n",
    "        summed_distances = 0\n",
    "        for e, token in enumerate(shorter):\n",
    "            pos = en+e\n",
    "            if pos < len(longer):\n",
    "                s = edit_distance(token, longer[pos])\n",
    "            else:\n",
    "                s = len(token)\n",
    "            summed_distances += s\n",
    "        print(comp, shorter, summed_distances)\n",
    "        if summed_distances < best_distance:\n",
    "            best_distance = summed_distances\n",
    "            best_start = en\n",
    "    return (best_distance, shorter, longer[best_start: best_start+len(shorter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missouri missouri a bone of contention\n",
      "lucien carr\n",
      "houghton american commonwealths boston itoughto. sftfltn co.\n",
      "\n",
      "\n",
      "the lord byron self-revealed\n",
      "lord johnson\n",
      "john scribner's\n",
      "\n",
      "\n",
      "carnival carnival\n",
      "compton aldavini\n",
      "d. d. appleton & company\n",
      "\n",
      "\n",
      "photographic \n",
      "george fox\n",
      "e. e. b. treat\n",
      "\n",
      "\n",
      "life life and letters of dante gabriel rossetti\n",
      "william william michael rossetti\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-21c4928a424a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reviewed_book_title_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"reviewed_author_name_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"reviewed_book_publisher_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(edit_distance(ground_truth_lists[e][key], comp))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_most_common(counter):\n",
    "    try:\n",
    "        entity = counter.most_common(1)[0][0].lower()\n",
    "    except:\n",
    "        entity = \"\"\n",
    "    return entity\n",
    "\n",
    "for e,i in enumerate(review_instances):\n",
    "    title = get_most_common(i.top_titles)\n",
    "    pub = get_most_common(i.top_publishers)\n",
    "    auth = get_most_common(i.top_authors)\n",
    "    \n",
    "    for key, comp in [(\"reviewed_book_title_tokens\", title), (\"reviewed_author_name_tokens\", auth), (\"reviewed_book_publisher_tokens\", pub)]:\n",
    "        print(ground_truth_lists[e][key][0], comp)\n",
    "        #print(edit_distance(ground_truth_lists[e][key], comp))\n",
    "    print('\\n')\n",
    "\n",
    "    # check if candidate is an empty string\n",
    "    # replace things like ampersands, possessives, punctuation\n",
    "    # tokenize and limit title to four tokens ... what if the title candidate is words 4,5,6 and 7? \n",
    "    # remove function words\n",
    "    # standardize initial tokens\n",
    "    # handle more than one author in ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american ['houghton'] 7\n",
      "commonwealths ['houghton'] 11\n",
      "boston ['houghton'] 4\n",
      "itoughto ['houghton'] 3\n",
      "sftfltnco ['houghton'] 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, ['houghton'], ['itoughto'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#compare_candidates_and_labels(['bone', 'with', 'contention'], ['missouri', 'a', 'bone', 'of', 'contention'])           \n",
    "compare_candidates_and_labels(['houghton'], ['american', 'commonwealths', 'boston', 'itoughto', 'sftfltn' 'co'])\n",
    "            \n",
    "    # handle alignment tails by adding tail token lengths to edit distance \n",
    "\n",
    "# gather best distances \n",
    "# narrow the match list by best fields and year\n",
    "# pick top from what remains ... rank by total distance, subsort by number of perfect matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_text_merged = []\n",
    "\n",
    "# loop candidate data\n",
    "for e,t in enumerate(review_objects):\n",
    "    # true label is titles[e]\n",
    "    # get text from various attributes (title, publisher, author) \n",
    "    # tokenize\n",
    "    # remove function words and punctuation? \n",
    "    text_merged = [] \n",
    "    for z in [t.title_candidates, t.author_candidates, t.publisher_candidates]:\n",
    "        this_list = []\n",
    "        #z is a dictionary or Counter\n",
    "        for k,v in z.items():\n",
    "            #screen out 'review no title'\n",
    "            tokens = word_tokenize(k.lower())\n",
    "            tokens = [j.replace(\"&\", \"and\") for j in tokens]\n",
    "            tokens = [j for j in tokens if j not in string.punctuation]\n",
    "            #for r in range(v):\n",
    "            this_list.extend(tokens)\n",
    "        match_indices = []\n",
    "        for n,t in enumerate(this_list):\n",
    "            if t == 'review':\n",
    "                try:\n",
    "                    if this_list[n+1] == 'no':\n",
    "\n",
    "                        try:\n",
    "                            if this_list[n+2] == 'title':\n",
    "                                match_index = n\n",
    "                                match_indices.append(n)\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "        for m in match_indices:\n",
    "            this_list[m] = ''\n",
    "            this_list[m+1] = ''\n",
    "            this_list[m+2] = ''\n",
    "        this_list = [j for j in this_list if j !='']\n",
    "        text_merged.extend(this_list)\n",
    "    all_text_merged.append(text_merged)\n",
    "    # the true vector becomes comparison_set[-1]\n",
    "    comparison_set = [Counter(u) for u in ground_truth_lists] + [Counter(text_merged)]\n",
    "    \n",
    "    # compare \n",
    "    vectorizer = DictVectorizer()\n",
    "    X = vectorizer.fit_transform(comparison_set)\n",
    "    vectors = X.toarray()\n",
    "    # loop all, get similarity, last one is always 1.0\n",
    "    scores = []\n",
    "    for v in vectors:\n",
    "        score = cosine_similarity([v], [vectors[-1]])\n",
    "        scores.append(score)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_merged[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often is the right answer the top answer? how often is the correct match in the top 5?\n",
    "output = []\n",
    "for e, score_grid in enumerate(all_scores):\n",
    "    df = pd.DataFrame()\n",
    "    df['score'] = [i[0][0] for i in score_grid][:-1]\n",
    "    df['title'] = titles\n",
    "    match = []\n",
    "    for i in range(len(titles)):\n",
    "        if e == i:\n",
    "            match.append('yes')\n",
    "        else:\n",
    "            match.append('no')\n",
    "    df['match'] = match\n",
    "    output.append(df.sort_values(by=\"score\", ascending=False).reset_index(drop=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = []\n",
    "accuracy = []\n",
    "\n",
    "for r in range(1, 562):\n",
    "    results = []\n",
    "    for i in output:\n",
    "        df_n = i.iloc[:r]\n",
    "        # check if 'yes' is in df_n\n",
    "        result = len(df_n.loc[df_n['match'] == 'yes']) > 0\n",
    "        results.append(result)\n",
    "    acc = len([i for i in results if i])/len(results) \n",
    "    top_n.append(r)\n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.lineplot(x=top_n, y=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_match = []\n",
    "top_five = []\n",
    "top_ten = []\n",
    "top_25 = []\n",
    "top_50 = []\n",
    "top_100 = []\n",
    "top_200 = []\n",
    "for i in output:\n",
    "    df_five = i.iloc[:5]\n",
    "    df_ten = i.iloc[:10]\n",
    "    df_25 = i.iloc[:25]\n",
    "    df_50 = i.iloc[:50]\n",
    "    df_100 = i.iloc[:100]\n",
    "    df_200 =i.iloc[:200]\n",
    "    top_match.append(i.iloc[0]['match'] == 'yes')\n",
    "    top_five.append(len(df_five.loc[df_five['match'] == 'yes']) > 0)\n",
    "    top_ten.append(len(df_ten.loc[df_ten['match'] == 'yes']) > 0)\n",
    "    top_25.append(len(df_25.loc[df_25['match'] == 'yes']) > 0)\n",
    "    top_50.append(len(df_50.loc[df_50['match'] == 'yes']) > 0)\n",
    "    top_100.append(len(df_100.loc[df_100['match'] == 'yes']) > 0)\n",
    "    top_200.append(len(df_200.loc[df_200['match'] == 'yes']) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55.97% whole vector\n",
    "len([i for i in top_match if i])/len(top_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 73% in top five\n",
    "len([i for i in top_five if i])/len(top_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% in top ten\n",
    "len([i for i in top_ten if i])/len(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#87.5% in top 25\n",
    "len([i for i in top_25 if i])/len(top_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#91% in top 50\n",
    "len([i for i in top_50 if i])/len(top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in top_200 if i])/len(top_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = []\n",
    "mismatch_candidate_tokens = []\n",
    "for e, df in enumerate(output):\n",
    "    if df.iloc[0]['match'] != 'yes':\n",
    "        mismatches.append(df)\n",
    "        mismatch_candidate_tokens.append(all_text_merged[e])\n",
    "mismatches[2].iloc[0]['title'], mismatches[2].loc[mismatches[2]['match'] == 'yes'].iloc[0]['title'], mismatch_candidate_tokens[2]\n",
    "mismatches[2].iloc[24]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#r = requests.get(\"https://www.worldcat.org/search?q=ti%3Ahuckleberry+finn&fq=yr%3A1865..1925+%3E+%3E+x0%3Abook&qt=advanced&dblist=638\")\n",
    "# page 2 ... \"https://www.worldcat.org/search?q=ti%3Ahuckleberry+finn&fq=yr%3A1865..1925+%3E+%3E+x0%3Abook&dblist=638&start=11&qt=page_number_link\"\n",
    "bs = BeautifulSoup(r.text)\n",
    "bs.find_all(\"span\", {\"class\":\"itemPublisher\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
