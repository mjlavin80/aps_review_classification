{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "- import various helpers, load data, select reviews by status and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "\n",
    "from application.review_obj_class import ReviewObj\n",
    "\n",
    "from application.text_preprocessing import preprocess_text\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "import database.models as models\n",
    "\n",
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "\n",
    "len(aps_details_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_parsed = [ReviewObj(i.record_id, i.full_text) for i in aps_details_single if i.reviewed_book_publisher !='']\n",
    "publishers = [i.reviewed_book_publisher for i in aps_details_single if i.reviewed_book_publisher !='']\n",
    "len(publishers)\n",
    "#reviews_parsed[0].cleaned_text\n",
    "#reviews_parsed[0].cleaned_toks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_parsed) == len(publishers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publisher Names\n",
    "\n",
    "The overall approach here is to fuzzy match uppercase N-Grams with known publisher names, and/or key terms like company and inc. Very much like the title function but it drops anything that doesn't meet \"publisher\" criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_function_tail(sequence):\n",
    "    if sequence[-1].lower() in stopwords.words('english'):\n",
    "        sequence.pop()\n",
    "        return remove_function_tail(sequence)\n",
    "    else:\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pub names from db\n",
    "known_publishers = list(set(publishers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 102), ('&', 92), ('Co', 81), ('Company', 44), (',', 35), ('The', 25), ('and', 18), ('Publishing', 16), ('C.', 13), ('H.', 13), (\"'s\", 11), ('A.', 9), ('Son', 8), ('B.', 8), ('Sons', 8), ('Brothers', 7), ('Macmillan', 7), ('Lippincott', 7), ('Press', 7), ('Houghton', 7), ('E.', 6), ('D.', 6), ('Appleton', 6), ('Harper', 6), ('Scribner', 6), ('University', 6), ('Mifflin', 6), ('F.', 5), ('W.', 5), ('P.', 5), ('Dutton', 5), ('J.', 5), ('G.', 4), ('Revell', 4), ('Armstrong', 4), ('J', 4), ('Putnam', 4), ('James', 4), ('of', 4), ('R.', 4), ('Baker', 3), ('Henry', 3), ('Stokes', 3), ('Duffield', 3), ('Marshall', 3), ('McClurg', 3), ('Little', 3), ('Brown', 3), ('Lea', 3), ('Saunders', 3), ('Dodd', 3), ('Mead', 3), ('Wells', 3), ('Pub', 3), ('Funk', 3), ('Wagnalls', 3), ('McClure', 3), ('Cassell', 3), ('Society', 3), ('Bros', 3), ('Boni', 3), ('Liveright', 3), ('Charles', 3), ('John', 3), ('Sherman', 2), ('Frederick', 2), ('Knopf', 2), ('Holt', 2), ('Jones', 2), ('B', 2), ('Treat', 2), ('Geo', 2), ('Ellis', 2), ('Robert', 2), ('Doran', 2), ('Page', 2), ('New', 2), ('York', 2), ('American', 2), ('Lawyers', 2), ('Callaghan', 2), ('Benziger', 2), ('Doubleday', 2), ('William', 2), ('Harcourt', 2), ('Brace', 2), ('Arena', 2), ('Wood', 2), ('Thomas', 2), ('Ticknor', 2), ('Fowler', 2), ('Hodder', 2), ('Stoughton', 2), ('Chicago', 2), ('Century', 2), ('Griggs', 2), ('Fleming', 2), ('Association', 2), ('Green', 2), ('Book', 2)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "pub_tokens = [word_tokenize(i) for i in known_publishers]\n",
    "flat_list = [item for sublist in pub_tokens for item in sublist]\n",
    "Counter(flat_list).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends = ['company','co','incorporated','inc','firm','press','group','publishers','publishing', \\\n",
    "            'publications','pub','books','ltd','limited','society','house','associates', 'book', 'university']\n",
    "pub_ends = [x.capitalize() for x in pub_ends]\n",
    "#pub_ends_list = '|'.join([x.capitalize()+'\\.?(?!\\w)' for x in pub_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['III', 'THE', 'WOMAN', 'WITH', 'EMPTY', 'HANDS', '!', '*', 'This', 'record']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_toks = reviews_parsed[507].cleaned_toks\n",
    "test_toks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'III THE WO'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = reviews_parsed[507].cleaned_text\n",
    "test_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for fuzzy match in free text\n",
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "def match_known_publishers(text, k_p):\n",
    "    all_matches = {}\n",
    "    for p in k_p:\n",
    "        #base fuzziness on length of pubname\n",
    "        if len(p) < 10:\n",
    "            fuzz=0\n",
    "        elif len(p) > 9 and len(p) < 20:\n",
    "            fuzz=1\n",
    "        else:\n",
    "            fuzz=3\n",
    "        matches = find_near_matches(p, text, max_l_dist=fuzz)\n",
    "        if len(matches) > 0:\n",
    "            match_strings = [text[m.start:m.end] for m in matches]\n",
    "            for i in match_strings:\n",
    "                try:\n",
    "                    all_matches[p].append(c)\n",
    "                except:\n",
    "                    all_matches[p] = [c,]\n",
    "    for k,v in all_matches.items():\n",
    "        if len(v) == 1 and k == v[0]:  \n",
    "            return (\"found\", [k,])\n",
    "        else:\n",
    "            result = list(all_matches.keys())\n",
    "            if len(result) > 0:\n",
    "                return (\"found\", result)\n",
    "            else:\n",
    "                return (\"not found\", result)\n",
    "    \n",
    "\n",
    "def match_pub_end_sequences(tokens, pub_ends, k_p):\n",
    "    title_candidates = [list(),]\n",
    "    for token in tokens:\n",
    "        if token.istitle() or token in ['and', '&'] or token in string.punctuation:\n",
    "            if len(title_candidates[-1]) > 0:\n",
    "                if token not in string.punctuation:\n",
    "                    title_candidates[-1].append(token)\n",
    "            else:\n",
    "                if token.istitle():\n",
    "                    title_candidates[-1].append(token)\n",
    "        else:\n",
    "            if len(title_candidates[-1]) > 0:\n",
    "                title_candidates.append(list())\n",
    "    \n",
    "    matches = []\n",
    "    for sequence in title_candidates:\n",
    "        for token in sequence:\n",
    "            normed_token = token.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "            if normed_token in [i.lower() for i in pub_ends]:\n",
    "                matches.append(sequence)\n",
    "                break\n",
    "    result = [] \n",
    "    for sequence in matches:\n",
    "        r, this_result = match_known_publishers(\" \".join(sequence), k_p)\n",
    "        \n",
    "        if len(this_result) > 0:\n",
    "            result.append(this_result)\n",
    "    if len([\" \".join(i) for i in result]) > 0:\n",
    "        return (\"found\", [\" \".join(i) for i in result])\n",
    "    else:\n",
    "        return (\"novel\", [\" \".join(i) for i in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('found', ['Dodd, Mead, and Company', 'Dodd, Mead and Company'])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tests\n",
    "result, publisher_candidates = match_known_publishers(test_text, known_publishers)\n",
    "if len(publisher_candidates) == 0:\n",
    "    result, publisher_candidates = match_pub_end_sequences(test_toks, pub_ends, known_publishers)\n",
    "    \n",
    "#[\" \".join(i[1]) for i in match_pub_end_sequences(test_toks, pub_ends, known_publishers)]\n",
    "result, publisher_candidates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_publisher_matches = {}\n",
    "\n",
    "# run on all reviews, return matches, novel, or no match\n",
    "for review in reviews_parsed:\n",
    "    \n",
    "    result, publisher_candidates = match_known_publishers(review.cleaned_text, known_publishers)\n",
    "    \n",
    "    if len(publisher_candidates) == 0:        \n",
    "        result, publisher_candidates = match_pub_end_sequences(review.cleaned_toks, pub_ends, known_publishers)\n",
    "    \n",
    "    if len(publisher_candidates) > 0:\n",
    "        top_publisher_candidate = publisher_candidates[0]\n",
    "    else:\n",
    "        result = \"not found\"\n",
    "        top_publisher_candidate = ''\n",
    "    \n",
    "    try:\n",
    "        all_publisher_matches[\"type\"].append(result) \n",
    "    except:\n",
    "        all_publisher_matches[\"type\"] = [result,]\n",
    "        \n",
    "    try:\n",
    "        all_publisher_matches[\"results\"].append(top_publisher_candidate)\n",
    "    except:\n",
    "        all_publisher_matches[\"results\"] = [top_publisher_candidate,]\n",
    "    try:\n",
    "        all_publisher_matches[\"match_number\"].append(len(publisher_candidates))\n",
    "    except:\n",
    "        all_publisher_matches[\"match_number\"] = [len(publisher_candidates),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://viaf.org/viaf/159556432']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build viaf store, add columns for comparison\n",
    "pub_tuples = [(i.reviewed_book_publisher, i.reviewed_book_publisher_viaf_match) for i in aps_details_single if i.reviewed_book_publisher !='']\n",
    "viaf_store = {}\n",
    "count = 0\n",
    "for i,j in pub_tuples:\n",
    "    if j == '' or not j:\n",
    "        try: \n",
    "            is_in = viaf_store[i]\n",
    "        except:\n",
    "            viaf_store[i] = [count,]\n",
    "            count +=1\n",
    "    else:\n",
    "        try:\n",
    "            if j not in viaf_store[i]:\n",
    "                viaf_store[i].append(j)\n",
    "        except:\n",
    "            viaf_store[i] = [j,]\n",
    "viaf_store['Houghton, Mifflin & Company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733009708737864"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_publisher_matches)\n",
    "df['recorded_publisher'] = publishers\n",
    "\n",
    "top_result_viaf = []\n",
    "for i in list(df['results']):\n",
    "    try: \n",
    "        top_result_viaf.append(viaf_store[i][0])\n",
    "    except: \n",
    "        top_result_viaf.append(None)\n",
    "        \n",
    "recorded_viaf = []\n",
    "for i in list(df['recorded_publisher']):\n",
    "    try: \n",
    "        recorded_viaf.append(viaf_store[i][0])\n",
    "    except: \n",
    "        recorded_viaf.append(None)\n",
    "        \n",
    "df['recorded_viaf'] = recorded_viaf\n",
    "df['top_result_viaf'] = top_result_viaf\n",
    "df\n",
    "#df.loc[(df['type'] == 'match') & (df['match_number'] == 1)]\n",
    "len(df.loc[df['recorded_viaf'] == df['top_result_viaf']])/len(df.loc[df['type'] == 'found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22286821705426357"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['recorded_viaf'] != df['top_result_viaf']])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02131782945736438, 0.20155038759689922)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped = len(df.loc[(df['type'] != 'found')])\n",
    "correct_or_skipped = len(df.loc[df['recorded_viaf'] == df['top_result_viaf']])+len(df.loc[(df['type'] != 'found')])\n",
    "total = len(df)\n",
    "1-correct_or_skipped/total, skipped/total\n",
    "\n",
    "# 20.16% of reviews, no publisher found or novel publisher suggested\n",
    "# 77.71% of reviews matched and are correct\n",
    "# 2.13% are incorrect ... match could be in the ranked list for six of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc[(df['recorded_viaf'] != df['top_result_viaf']) & df['match_number'] > 0]\n",
    "#df.loc[(df['type'] == 'found') & (df['recorded_viaf'] != df['top_result_viaf'])]\n",
    "len(df.loc[df['type'] == 'not found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['type'] == 'novel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess accuracy of review.pubnames\n",
    "\n",
    "all_publisher_matches = {}\n",
    "\n",
    "# run on all reviews, return matches, novel, or no match\n",
    "for review in reviews_parsed:\n",
    "    \n",
    "    result, publisher_candidates = match_known_publishers(review.cleaned_text, known_publishers)\n",
    "    \n",
    "    if len(publisher_candidates) == 0:        \n",
    "        result, publisher_candidates = match_pub_end_sequences(review.cleaned_toks, pub_ends, known_publishers)\n",
    "    \n",
    "    if len(publisher_candidates) > 0:\n",
    "        top_publisher_candidate = publisher_candidates[0]\n",
    "    else:\n",
    "        result = \"not found\"\n",
    "        top_publisher_candidate = ''\n",
    "    \n",
    "    try:\n",
    "        all_publisher_matches[\"type\"].append(result) \n",
    "    except:\n",
    "        all_publisher_matches[\"type\"] = [result,]\n",
    "        \n",
    "    try:\n",
    "        all_publisher_matches[\"results\"].append(top_publisher_candidate)\n",
    "    except:\n",
    "        all_publisher_matches[\"results\"] = [top_publisher_candidate,]\n",
    "    try:\n",
    "        all_publisher_matches[\"match_number\"].append(len(publisher_candidates))\n",
    "    except:\n",
    "        all_publisher_matches[\"match_number\"] = [len(publisher_candidates),]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
