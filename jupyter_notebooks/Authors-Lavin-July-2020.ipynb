{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "- import various helpers, load data, select reviews by status and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "\n",
    "from application.review_obj_class import ReviewObj\n",
    "\n",
    "from application.text_preprocessing import preprocess_text\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "import database.models as models\n",
    "\n",
    "# load full text from db\n",
    "aps_details_single = models.Review().query.filter(models.Review.status.in_(('needs_crosscheck', 'done'))).filter(models.Review.review_type == 'single_focus').all()\n",
    "\n",
    "len(aps_details_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_parsed = [ReviewObj(i.record_id, i.full_text) for i in aps_details_single if i.reviewed_author_name !='' and i.reviewed_author_name is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = [i.reviewed_author_name for i in aps_details_single if i.reviewed_author_name !='' and i.reviewed_author_name is not None]\n",
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Person Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Missouri: '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use for titles? \n",
    "reviews_parsed[0].no_pubs_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr. Fox, Dr. Fox]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consolidate duplicates? \n",
    "reviews_parsed[3].person_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_authors = list(set(authors))\n",
    "len(known_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lord Byron; W. A. Lewis Bettany'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "def match_known_authors(text, k_a):\n",
    "    all_matches = {}\n",
    "    for a in k_a:\n",
    "        # a might be multiple\n",
    "        candidates = a.split(';')\n",
    "        for can in candidates:\n",
    "        #base fuzziness on length of author name\n",
    "            if len(can) < 10:\n",
    "                fuzz=0\n",
    "            elif len(can) > 9 and len(can) < 20:\n",
    "                fuzz=1\n",
    "            else:\n",
    "                fuzz=3\n",
    "            matches = find_near_matches(can, text, max_l_dist=fuzz)\n",
    "            if len(matches) > 0:\n",
    "                match_strings = [text[m.start:m.end] for m in matches]\n",
    "                for i in match_strings:\n",
    "                    try:\n",
    "                        all_matches[can].append(i)\n",
    "                    except:\n",
    "                        all_matches[can] = [i,]\n",
    "        for k,v in all_matches.items():\n",
    "            if len(v) == 1 and k == v[0]:  \n",
    "                return (\"found\", [k,])\n",
    "    result = list(all_matches.keys())\n",
    "    if len(result) > 0:\n",
    "        return (\"found\", result)\n",
    "    else:\n",
    "        return (\"not found\", result)\n",
    "\n",
    "def match_surname(text, k_a):\n",
    "    all_matches = {}\n",
    "    for a in k_a:\n",
    "        # a might be multiple\n",
    "        candidates = a.split(';')\n",
    "        for can in candidates:\n",
    "            surname = can.split()[-1]\n",
    "            #base fuzziness on length of author name\n",
    "            if len(surname) < 10:\n",
    "                fuzz=0\n",
    "            elif len(surname) > 9 and len(surname) < 20:\n",
    "                fuzz=1\n",
    "            else:\n",
    "                fuzz=3\n",
    "            matches = find_near_matches(surname, text, max_l_dist=fuzz)\n",
    "            if len(matches) > 0:\n",
    "                match_strings = [text[m.start:m.end] for m in matches]\n",
    "                for i in match_strings:\n",
    "                    try:\n",
    "                        all_matches[can].append(i)\n",
    "                    except:\n",
    "                        all_matches[can] = [i,]\n",
    "        for k,v in all_matches.items():\n",
    "            if len(v) == 1 and k == v[0]:  \n",
    "                return (\"found\", [k,])\n",
    "    result = list(all_matches.keys())\n",
    "    if len(result) > 0:\n",
    "        return (\"found\", result)\n",
    "    else:\n",
    "        return (\"not found\", result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Carr ('found', ['Lucien Carr', 'Clark E. Carr'])\n",
      "Mr. Carr ('found', ['Lucien Carr', 'Clark E. Carr'])\n"
     ]
    }
   ],
   "source": [
    "for i in reviews_parsed[0].person_names:\n",
    "    #print(i, match_known_authors(i, known_authors))\n",
    "    print(i, match_surname(i, known_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_author_matches = {}\n",
    "\n",
    "# run on all reviews, return matches, novel, or no match\n",
    "for review in reviews_parsed:\n",
    "    \n",
    "    results = {}\n",
    "    names = list(set(review.person_names))\n",
    "    for i in names:\n",
    "        # function to fuzzy match known authors\n",
    "        result, author_candidates = match_known_authors(i, known_authors)\n",
    "        if len(author_candidates) == 0:\n",
    "            result, author_surname_candidates = match_surname(i, known_authors)\n",
    "            if len(author_surname_candidates) > 0:\n",
    "                for z in author_surname_candidates:\n",
    "                    if len(z.strip()) > 2:\n",
    "                        try:\n",
    "                            results[i].append(z)\n",
    "                        except:\n",
    "                            results[i] = [z,]\n",
    "        else:\n",
    "            for z in author_candidates:\n",
    "                if len(z.strip()) > 2:\n",
    "                    try:\n",
    "                        results[i].append(z)\n",
    "                    except:\n",
    "                        results[i] = [z,]\n",
    "    \n",
    "    if len(results.keys()) == 0:        \n",
    "        result = \"not found\"\n",
    "\n",
    "    if len(review.person_names) == 0:        \n",
    "        result = \"not found\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        all_author_matches[\"type\"].append(result) \n",
    "    except:\n",
    "        all_author_matches[\"type\"] = [result,]\n",
    "        \n",
    "    try:\n",
    "        all_author_matches[\"results\"].append(results)\n",
    "    except:\n",
    "        all_author_matches[\"results\"] = [results,]\n",
    "    try:\n",
    "        all_author_matches[\"match_number\"].append(len(results.keys()))\n",
    "    except:\n",
    "        all_author_matches[\"match_number\"] = [len(results.keys()),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://viaf.org/viaf/71253540']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build viaf store, add columns for comparison\n",
    "author_tuples = [(i.reviewed_author_name, i.reviewed_author_viaf_match) for i in aps_details_single if i.reviewed_author_name is not None and i.reviewed_author_name !='']\n",
    "viaf_store = {}\n",
    "count = 0\n",
    "for f,g in author_tuples:\n",
    "    i = f.split(\";\")\n",
    "    uris = g.split(\";\")\n",
    "    i = f.split(\";\")\n",
    "    uris = g.split(\";\")\n",
    "    tail = []\n",
    "    if len(i) > len(uris):\n",
    "        for m in range(len(i) - len(uris)):\n",
    "            tail.append('not available')\n",
    "        uris = uris+tail\n",
    "    if len(uris) > len(i):\n",
    "        uris = uris[:4]\n",
    "        i = i[:4]\n",
    "        \n",
    "    for e, j in enumerate(uris):\n",
    "        if j == '' or j.lower() == \"not available\":\n",
    "            try: \n",
    "                is_in = viaf_store[i[e]]\n",
    "            except:\n",
    "                viaf_store[i[e]] = [count,]\n",
    "                count +=1\n",
    "        else:\n",
    "            try:\n",
    "                if j not in viaf_store[i[e]]:\n",
    "                    viaf_store[i[e]].append(j)\n",
    "            except:\n",
    "                viaf_store[i[e]] = [j,]\n",
    "viaf_store['Lucien Carr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "top_candidates = []\n",
    "for r in all_author_matches['results']:\n",
    "    top = []\n",
    "    for c in r.values():\n",
    "        top_match = random.choice(c)\n",
    "        top.append(top_match) \n",
    "    top.sort()\n",
    "    top = list(set(top))\n",
    "    top_candidates.append(\";\".join(top))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230769230769231"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_author_matches)\n",
    "df['recorded_authors'] = authors\n",
    "df['top_candidates'] = top_candidates\n",
    "#df['recorded_viaf'] = recorded_viaf\n",
    "#df['top_result_viaf'] = top_result_viaf\n",
    "df = df.drop(['results'], axis=1)\n",
    "len(df.loc[(df['match_number'] == 1) & (df['recorded_authors'] == df['top_candidates'])])/len(df.loc[(df['match_number'] == 1)])\n",
    "#75.8% accurate when one author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_authors = []\n",
    "for row in df.iterrows():\n",
    "    true_authors.extend(row[1]['recorded_authors'].split(\";\"))\n",
    "len(true_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 90, 297)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives_count = []\n",
    "missed_author_count = []\n",
    "matched_correctly_count = []\n",
    "perfect_match_count = []\n",
    "\n",
    "for row in df.iterrows():\n",
    "    candidate_list = [i.strip() for i in row[1]['top_candidates'].split(\";\") if i !='']\n",
    "    target_list = [i.strip() for i in row[1]['recorded_authors'].split(\";\") if i !='']\n",
    "    if len(candidate_list) > 0:\n",
    "        # number of matches and number of false positives\n",
    "        fp = 0\n",
    "        matches = 0\n",
    "        for name in candidate_list:\n",
    "            if name not in target_list:\n",
    "                fp += 1\n",
    "\n",
    "            else:\n",
    "                matches += 1\n",
    "        false_positives_count.append(fp)\n",
    "        matched_correctly_count.append(matches)\n",
    "\n",
    "        # number of missed authors\n",
    "        fn = 0\n",
    "        for name in target_list:\n",
    "            if name not in candidate_list:\n",
    "                fn +=1\n",
    "        missed_author_count.append(fn)\n",
    "\n",
    "        # perfect match?\n",
    "        if fn == 0 and fp == 0:\n",
    "            perfect = True\n",
    "        else:\n",
    "            perfect = False\n",
    "\n",
    "        perfect_match_count.append(perfect)\n",
    "sum(false_positives_count), sum(missed_author_count), sum(matched_correctly_count)\n",
    "#(149, 35, 149)\n",
    "# including single match (188, 84, 309)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5478260869565217"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in perfect_match_count if i == True])/len(perfect_match_count)\n",
    "#0.3157894736842105\n",
    "#0.3157894736842105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
