{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from application.name_obj_classes import PubName, PersonName, remove_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.review_obj_class import ReviewObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.text_preprocessing import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in files\n",
    "directory = \"../../aps_reviews_50/aps_reviews/\"\n",
    "filenames = os.listdir(directory)\n",
    "txts = []\n",
    "for file in filenames:\n",
    "    with open(directory + file) as f:\n",
    "        txts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['136726613', '90142613', '90390665', '124486140', '126315326', '136992742', '137651039', '89668273', '136971619', '90313218', '128376070', '124688361', '124882533', '89639059', '88461015', '124190789', '136902134', '90180084', '137244878', '88721263', '137412078', '89675095', '760950213', '124217248', '853770606', '137195890', '125727674', '88797650', '89649761', '90967694', '89672866', '89674750', '89635917', '124196531', '128176513', '88477095', '125715359', '124189638', '136887509', '90554411', '90186165', '125502663', '125724646', '124740955', '124707428', '89644579', '137072896', '136685639', '126788760', '89671107']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.split('.')[0] for x in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Publisher Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pub_matches(match_list):\n",
    "    cleaned_matches = []\n",
    "    for match in match_list:\n",
    "        index_to_start = 0\n",
    "        for i, x in enumerate(match[1].split()):\n",
    "            if x[0].islower() and x[0]!='&':\n",
    "                index_to_start = i+1\n",
    "        cleaned_matches.append(' '.join(match[1].split()[index_to_start:]))\n",
    "    return cleaned_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dash_for_pub(pub_match):\n",
    "    return re.sub(r'(?<!/w)-(?!/w)', '', pub_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends = ['company','co','incorporated','inc','firm','press','group','publishers','publishing',\n",
    "                    'publications','pub','books','ltd','limited','society','house','associates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends_list = '|'.join([x.capitalize()+'\\.?(?!\\w)' for x in pub_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_ends.extend([x.capitalize() for x in pub_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company', 'co', 'incorporated', 'inc', 'firm', 'press', 'group', 'publishers', 'publishing', 'publications', 'pub', 'books', 'ltd', 'limited', 'society', 'house', 'associates', 'Company', 'Co', 'Incorporated', 'Inc', 'Firm', 'Press', 'Group', 'Publishers', 'Publishing', 'Publications', 'Pub', 'Books', 'Ltd', 'Limited', 'Society', 'House', 'Associates']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "    for e, index in enumerate(indices):\n",
    "        \n",
    "        if (e==len(indices)-1):\n",
    "            end_index = -1\n",
    "        else:\n",
    "            end_index = indices[e+1][0]\n",
    "        \n",
    "        end_span = len(txt[indices[e][0]:end_index])   \n",
    "        get_match = re.finditer('[A-Z]\\w+[^A-Z]|[A-Z].[^A-Z]', txt[indices[e][0]:end_index])\n",
    "        matches = [(m.span(), m.group()) for m in get_match]\n",
    "        matches.reverse()\n",
    "        \n",
    "        for n, m in enumerate(matches):\n",
    "            if n<len(matches)-1:\n",
    "                if (m[0][1] != matches[n-1][0][0]):\n",
    "                    end_span = m[0][1]\n",
    "        \n",
    "        result = txt[indices[e][0]:(indices[e][0] + end_span - 1)]\n",
    "        \n",
    "        if len(result) > len(indices[e][1]):\n",
    "            names.append(txt[indices[e][0]:(indices[e][0] + end_span - 1)])\n",
    "            spans.append(indices[e][0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ split into tokens\n",
    "+ stop as soon \n",
    "+ stop as city names\n",
    "+ put word tokenizer in review obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "for filename, txt in zip([x.split('.')[0] for x in filenames], txts):\n",
    "    review_list.append(ReviewObj(filename, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = review_list[0].cleaned_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LITERARY', 'NOTES', '.', '-The', 'Chautauqua', 'department', 'of', '``', 'Wide', 'Awake', '``', 'is', 'now', 'published', 'separately', '.', '-Mr.', 'Charles', 'Dudley', 'Warner', 'has', 'written', 'for', '``', 'The', 'North', 'American', 'Review', '``', 'a', 'paper', 'on', 'prison', '.', '-Mr.', 'Vedder', \"'s\", 'illustrations', 'of', 'the', '``', 'Rubfilyfit', '``', 'have', 'found', 'a', 'great', 'admirer', 'in', 'the', 'Queen', 'of', 'Italy', '.', '-Cassell', '&', 'Co.', 'sill', 'shortly', 'publish', 'a', '``', 'Dictionary', 'of', 'English', ',', '``', 'by', 'Sidney', 'J', '.', 'Low', 'and', 'F.', 'S.', 'Pulling', '.', '-Professor', 'Thorold', 'Rogers', 'is', 'writing', 'a', 'worL', 'on', 'the', '``', 'of', 'the', 'Privileges', 'of', 'British', 'Citizenship.', '``', '-', '``', 'Mollie', 'Carew', '``', 'is', 'the', 'title', 'of', 'a', 'pleasant', 'story', 'by', 'A.', 'M.', 'W.', ',', 'just', 'published', 'by', 'E.', 'P.', 'Dutton', '&', 'Co.', ',', 'New', 'Yor', \"'\", '.', '-', '.-rs', '.', '(', 'MISS', 'i', ')', 'nas', 'written', 'tne', 'article', 'on', 'Mrs.', 'Browning', 'for', 'the', 'new', '``', 'Biograpbical', 'Dictionary.', '``', '-Chatto', '&', 'Windus', ',', 'the', 'Engllsh', 'publishers', ',', 'will', 'issue', 'during', 'the', 'coming', 'season', 'the', 'collected', 'essays', 'of', 'Mr.', 'Swinburne', '.', '-Dr.', 'William', \"'\", 'M.', 'Taylor', \"'s\", '``', 'Life', 'of', 'John', 'Knox', '``', 'is', 'announced', 'for', 'early', 'by', 'A.', 'C.', 'Armstrong', '&', 'Sons', ',', 'New', 'York', '.', '-The', '``', 'Athenmum', '``', 'reports', 'that', 'Mark', 'Twain', 'will', 'vis', 't', 'England', 'In', 'Mfay', ',', 'for', 'the', 'purpose', 'of', 'giving', 'readings', 'from', 'bis', 'own', 'writings', '.', '-The', '``', 'X1', 'of', 'Paris', '``', 'and', '``', 'Daiid', 'Conperfeld', ',', '``', 'I1lustrated', 'and', 'sold', 'in', 'penny', 'numbers', ',', 'are', 'running', 'neck', 'and', 'neck', 'in', 'Erance', '.', '-The', 'Appletons', \"'\", 'new', 'twenty-five-cent', 'series', 'of', 'Popular', 'Stories', 'has', 'proved', 'a', 'decided', 'success', ',', 'and', 'has', 'certainly', 'included', 'Eome', 'striking', 'novels', '.', '-Dr.', 'Geor6', 'Ebers', \"'\", 'latest', 'romance', ',', \"'\", '-', 'Serapls', ',', '``', 'has', 'been', 'translated', 'into', 'English', 'by', 'Clara', 'Bell', ',', 'and', 'published', 'by', 'W.', 'S.', 'Gottaberger', ',', 'of', 'this', 'city', '.', '-The', '``', 'Springlield', 'Republican', '``', 'has', 'arranged', 'for', 'a', 'of', 'short', 'stories', 'by', 'EngUsb', ',', 'tobe', 'published', 'In', 'its', 'Sunday', 'edition', '.', 's-Mr.', 'Julian', 'Hawthorne', 'has', 'written', 'a', 'new', 'story', ',', 'entitled', '``', 'The', 'Trial', 'of', 'Gideon', ',', '``', 'which', 'Is', 'to', 'be', 'by', 'Funk', '&', 'Wagnalls', 'some', 'time', 'during', 'the', 'spring', '.', '-Mr.', 'Julius', 'Chambers', ',', 'a', 'Philadelphia', 'journalist', ',', 'is', 'the', 'author', 'of', 'the', 'novel', '``', 'On', 'a', 'Margin', ',', '``', 'published', 'by.Forda', ',', 'Howard', '&', ',', 'and', 'which', 'is', 'having', 'a', 'large', 'tale', '.', '-The', '``', 'Works', 'of', 'Virgil', ',', '``', 'with', 'nores', 'by', 'Edward', 'Searing', ',', 'will', 'shortly', 'be', \"'\", 'by', 'A.', 'S.', 'Barnes', '&', 'Co.', ',', 'New', 'York', ',', 'In', 'a', 'single', 'illustrated', 'volume', 'of', '719', 'pages', '.', '-A', 'new', 'department', 'is', 'to', 'be', 'added', 'to', 'the', '``', 'North', 'American', 'Review', ',', '``', 'including', 'letters', 'commenting', 'upon', 'articles', 'which', 'have', 'appeared', 'in', 'the', '``', 'R', 'Review.', '``', '-The', 'third', 'series', 'of', 'the', 'Johns', 'Hopkins', 'Studies', 'in', 'Histor', '.', 'ical', 'and', 'Political', 'Science', 'begi', ':', 'a', 'with', 'the', 'publication', 'of', 'Dr.', 'i', '.', 'B.', 'Adams', \"'s\", 'paper', 'on', '``', 'Maryland', \"'s\", 'Influence', 'upon', 'Cessions', 'to', 'the', 'United', 'Statts.', '``', '-Ginn', ',', 'Heath', '&', 'Co.', 'will', 'publish', 'at', 'once', 'Pestalozi', \"'\", 'a', '``', 'Leonard', 'and', 'Gertrude', ',', '``', 'translated', 'and', 'abridged', 'by', 'Eva', 'Channing', ',', 'with', 'an', 'introduction', 'by', 'G.', 'Stanley', 'Ifail', '.', 'This', 'is', 'the', 'second', 'volume', 'of', 'the', 'series', 'of', '``', 'Educational', 'Classics.', '``', '-A', 'posthumous', 'study', '.', 'of', 'Victor', 'Hugo', 'by', 'the', 'eminent', 'French', 'critic', ',', 'Paul', 'de', 'St.', 'Victor', ',', 'has', 'been', 'recently', 'announced', '.', 'It', 'at', 'length', 'the', 'decay', 'ot', 'Victor', 'Hugo', \"'\", 'e', 'influence', 'and', 'the', 'rise', 'of', 'the', 'or', 'realistic', 'school', 'in', 'France', '.', '-E.', 'P.', 'Dutton', '&', 'Cov', 'will', 'Issue', ',', 'in', 'season', 'for', 'Easter', 'gifts', ',', 'several', 'little', 'books', 'with', '.', 'Awougthese', 'will', 'be', 'an', 'edition', 'of', 'Bryant', \"'s\", 'poem', ',', '``', 'The', 'Unknown', 'Way', ',', '``', 'illustrated', ';', '``', 'The', 'Celestial', 'Country.', '``', 'and', 'a', 'little', 'book', 'of', 'selections', 'called', '``', '-', 'Friend', 'to', 'Friend.', '``', '-The', 'Boston', '``', 'Literary', 'World', '``', 'of', 'February', '21', 'contains', 'a', 'long', 'and', 'careful', 'y', 'prepared', 'article', 'on', 'Amiel', '.', 'Amid', 'was', 'the', 'subject', 'of', 'a', 'recent', 'article', 'In', 'the', '``', 'Atlantic', 'Monthly', ',', '``', 'and', 'his', 'two', 'volumes', 'of', '``', 'fragments', ',', '``', 'which', 'have', 'now', 'reached', 'a', 'third', 'edition', ',', 'are', 'beginning', 'to', 'attract', 'on', 'this', 'side', 'of', 'the', 'Atlantic', '.', '-Thomas', 'Y.', 'Crowell', '&', 'Co.', ',', 'New', 'York', ',', 'have', 'Issued', 'the', 'prospectus', 'of', 'a', 'work', 'of', 'great', 'value', 'to', 'literary', 'workers', 'and', 'to', 'all', 'interested', 'in', 'literary', 'themes', ',', '``', 'Initials', 'and', 'Pseudonyms', ':', 'a', 'Dictionary', 'of', 'LiteraryDisguises', ',', '``', 'edited', 'by', 'William', 'Cuawing', '.', 'Mr.', 'Cushing', 'was', 'formerly', 'in', 'the', 'Harvard', 'Lbrary', ',', 'and', 'has', 'done', 'some', 'admirable', 'work', 'as', 'an', 'indexer', '.', '-The', 'first', 'publications', 'in', 'the', 'papers', 'of', 'the', 'American', 'Historical', 'Society', '(', 'New', 'York', ':', '(', 'G.', 'P.', 'PutnaWs', \"'\", 'dons', ')', 'ate', 'the', 'report', 'of', 'the', '-I', 'Organization', 'and', 'Proceedings', 'at', 'Saratoga', '``', 'last', 'September', ',', 'prepared', 'by', 'Dr.', 'Herbert', 'B.', 'Adam', '.', 'as', 'Secretary', ',', 'and', 'the', 'address', 'on', '``', 'Studies', 'in', 'General', 'History', 'and', 'the', 'History', 'of', 'Civilization', ',', '``', 'delivered', 'on', 'that', 'by', 'President', 'Andrew', 'D.', 'White', '.', '-In', 'addition', 'to', 'the', 'articles', 'on', 'the', 'engagement', 'between', 'the', '``', 'Monitor', '``', 'and', 'the', '-Merrimac', ',', '``', 'written', 'by', 'officers', 'of', 'both', 'vessels', ',', 'which', 'appear', 'in', 'the', 'March', 'number', 'of', '``', 'The', 'Century', ',', '``', 'CaptainEriceson', 'be', 'printed', 'in', 'an', 'early', 'number', 'of', 'the', 'same', 'magazine', ',', 'making', 'record', 'of', 'the', 'circumstances', 'attending', 'the', 'invention', 'of', 'the', '``', 'Mionitor', ',', '``', 'and', 'treating', 'ao', 'of', 'the', 'engagement', 'in', 'Hampton', 'Roads', '.', '-A', 'society', 'in', 'the', 'interest', 'of', 'dramatic', 'history', 'has', 'been', 'organized', 'in', 'this', 'city', ',', 'and', 'proposes', 'to', 'study', 'and', 'publish', 'books', 'concerning', 'the', 'stage', ',', 'to', 'collect', 'portraits', 'of', 'American', 'actors', '.', 'play-bills', '.', 'manuscripts', ',', 'autographs', ',', 'and', 'other', 'mattems', 'of', 'interest', 'to', 'the', 'student', 'of', 'the', 'American', 'drama', '.', 'It', 'Is', 'to', 'be', 'called', 'the', 'Dunlap', 'Society', ',', 'In', 'recognition', 'of', 'the', 'student', 'and', 'historian', 'of', 'the', 'American', 'stage', '.', 'Mr.', 'Brander', 'Matthews', ',', 'of', 'this', 'city', ',', 'is', 'to', 'he', 'Secretary', '.', '-The', 'February', 'number', 'of', '``', 'The', 'Pulpit', 'of', 'To-Day', '``', 'sermons', 'by', 'Canon', 'Liddon', 'on', '``', 'Mysteries', 'in', 'Religion', ',', '``', 'CanonFarrar', 'on', '``', 'Spirituality', ',', '``', 'Henry', 'Ward', 'Beecher', 'on', '``', 'The', 'Natural', 'and', 'the', 'Spiritual', ',', '``', 'and', '``', 'The', 'Use', 'and', 'Abnse', '.', '``', 'Dr.', 'Joseph', 'Parktercontinueshiseipositionuin', 'the', 'Book', 'of', 'Genesis', ',', 'and', 'Professor', 'E.', 'Johnsou', 'contributes', 'one', 'of', 'his', 'characteristic', 'studies', '.', 'Among', 'the', 'framework', 'there', 'are', 'outlines', 'by', 'Dr.', 'Malaren', ',', 'Dr.', 'Parker', ',', 'a', '.', 'Spurga', 'and', '-']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_part_of_pub(pub_part):\n",
    "    if (pub_part == 'and') or (pub_part =='&'):\n",
    "        return True\n",
    "    else:\n",
    "        return pub_part[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_part_of_pub('Egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubnames = []\n",
    "for e, tok in enumerate(toks):\n",
    "    if tok.replace(\",\",\"\").replace(\".\",\"\").replace('-',\"\") in pub_ends:\n",
    "        if is_part_of_pub(toks[e-1]):\n",
    "            pub_name = [tok]\n",
    "            pub_span = []\n",
    "            for pos in range(e-1, e-6, -1):\n",
    "                if toks[pos] == '.':\n",
    "                    break\n",
    "                elif not is_part_of_pub(toks[pos]):\n",
    "                    break\n",
    "                pub_name.append(toks[pos])\n",
    "                pub_span.append(pos)\n",
    "            pubnames.append((e, pub_span[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56, 54), (117, 113), (150, 149), (410, 406), (498, 496), (706, 702), (777, 775), (913, 912), (973, 972)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 118, 409, 497, 588, 706]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publishers(review):\n",
    "    \"\"\"\n",
    "    Takes a ReviewObj. \n",
    "    Returns a list of potential publishers. Searches using pub_ends, capitalization, and associates.\n",
    "    \n",
    "    For reference:\n",
    "    -------------\n",
    "    pub_ends = ['co','company','inc','incorporated','firm','press','group', 'pub','publishers','publishing',\n",
    "                    'publications','books','ltd','limited','society','house','associates']\n",
    "                    \n",
    "    pub_associates = ['sons','son','brother','brothers']\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pubs = []\n",
    "    spans = []\n",
    "    \n",
    "    txt = review.cleaned_text\n",
    "\n",
    "    p_iter = re.finditer(pub_ends_list, txt)\n",
    "    p_indices = [(m.end(), m.group()) for m in p_iter]\n",
    "    \n",
    "    for e, index in enumerate(p_indices):\n",
    "        if (e==0):\n",
    "            start_index = 0\n",
    "        else:\n",
    "            start_index = p_indices[e-1][0] - 1\n",
    "            \n",
    "        start_span = 0\n",
    "        \n",
    "        match = re.finditer(\"[A-Z]\\w+| & | and \", txt[start_index:index[0]])\n",
    "#         match = re.finditer(\"(?<= [^A-Z&\\.])[\\S]{,10} ?[A-Z][\\w&. ]*?\" + index[1] + '(?!\\w)', \n",
    "#                                 review.cleaned_text[start_index:index[0]])\n",
    "        #all_matches = [(m.span(), remove_dash_for_pub(m.group())) for m in match]\n",
    "        #print(all_matches)\n",
    "        matches = [(m.span(), m.group()) for m in match]\n",
    "        \n",
    "        for n, m in enumerate(matches):\n",
    "            #print(n,m)\n",
    "            if n<len(matches)-1:\n",
    "                #print(m[0][1], matches[n+1][0][0])\n",
    "                if (m[0][1] != matches[n+1][0][0]):\n",
    "                    start_span = matches[n+1][0][0]\n",
    "                    #print(start_span)\n",
    "        \n",
    "        result = txt[start_index + start_span:index[0]]\n",
    "        #print(result)\n",
    "        \n",
    "        if len(result) > len(p_indices[e][1]):\n",
    "            pubs.append(result)\n",
    "            spans.append(p_indices[e][0])\n",
    "\n",
    "\n",
    "    pubs = [PubName(word) for word in pubs]\n",
    "    \n",
    "    for pub in pubs:\n",
    "        pub.review_id = review.review_id\n",
    "    \n",
    "    for e, pub in enumerate(pubs):\n",
    "        pub.review_id = review.review_id\n",
    "        pub.review_loc = spans[e]\n",
    "    \n",
    "    return pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cassell & Co.', 'Dutton & Co.', 'Barnes & Co.', 'Heath & Co.', 'Crowell & Co.']\n",
      "['Holt & Co.']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['GINN & Co.', 'GINN & Co.', 'KnRR & Co.', 'Gl1N & Co.', 'Ginn & Co.', 'LIPizxcoTr & Co.', 'BROWN & Co.', ' & Co.', ' & Co.', ' & Co.', 'BARNES & Co.', 'LpnIrrcorr & Co.', 'RANDoLPHn & Co.']\n",
      "['Mead & Co.']\n",
      "[]\n",
      "[' & Co.']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Brown & Co.', 'Slead & Co.']\n",
      "['Sou & Co.']\n",
      "['Green & Co.', 'Mead & Co.', 'Randolph & Co.', 'Macmillan & Co.', 'Mifflin & Co.']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[' & Co.', 'Macmillan & Co.']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Ginn and Company', 'g Company', 'g Company']\n",
      "['Macmillan & Co.']\n",
      "[]\n",
      "[]\n",
      "['Mead & Co.', 'Dutton & Co.', 'Maynard & Co.']\n",
      "['Macmillan & Co.']\n",
      "[]\n",
      "[]\n",
      "['o Publishers']\n",
      "['MerriUCompany.']\n",
      "[]\n",
      "[]\n",
      "['Dutton & Co.']\n",
      "[]\n",
      "['CroweU & Co.']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Senate and House']\n",
      "['Appleton & Co.']\n",
      "[]\n",
      "['AtiSlin & Co.']\n"
     ]
    }
   ],
   "source": [
    "for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "    rev = ReviewObj(filename, txt)\n",
    "    print(get_publishers(rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136726613\n",
      "E. P. Dutton & Co.\n",
      "A. S. Barnes & Co.\n",
      "Ginn, Heath & Co.\n",
      "E. P. Dutton & Cov\n",
      "Thomas Y. Crowell & Co.\n",
      "American Historical Society\n",
      "American Historical Society\n",
      "Dunlap Society\n",
      "\n",
      "90142613\n",
      "The Gadfly. By E. L. VWynich. Henry Holt & Co.\n",
      "\n",
      "90390665\n",
      "\n",
      "124486140\n",
      "\n",
      "126315326\n",
      "136992742\n",
      "137651039\n",
      "BOSTON: GINN & Co.\n",
      "CAGO: CHAS. 1I. KnRR & Co.\n",
      "American Geographical Society\n",
      "BosTON: Gl1N & Co.\n",
      "Messrs. Ginn & Co.\n",
      "A. S. BARNES & Co.\n",
      "BOSTON AND LONDON GINN & Co.\n",
      "BOSTON: GINN & Co.\n",
      "CAGO: CHAS. 1I. KnRR & Co.\n",
      "BosTON: Gl1N & Co.\n",
      "Messrs. Ginn & Co.\n",
      "A. S. BARNES & Co.\n",
      "\n",
      "89668273\n",
      "\n",
      "136971619\n",
      "90313218\n",
      "\n",
      "128376070\n",
      "\n",
      "124688361\n",
      "124882533\n",
      "\n",
      "89639059\n",
      "Publishers\n",
      "\n",
      "88461015\n",
      "Robert Clarke Co\n",
      "Graphic Company\n",
      "\n",
      "124190789\n",
      "259. J. B. Lippincott Co.\n",
      "05. Macmillan Co.\n",
      "259. J. B. Lippincott Co.\n",
      "05. Macmillan Co.\n",
      "404. Maemillall Co.\n",
      "\n",
      "136902134\n",
      "\n",
      "90180084\n",
      "Mead & Co.\n",
      "& Co.\n",
      "Mead & Co.\n",
      "& Co.\n",
      "Houghton, Mifflin & Co.\n",
      "\n",
      "137244878\n",
      "\n",
      "88721263\n",
      "137412078\n",
      "\n",
      "89675095\n",
      "\n",
      "760950213\n",
      "124217248\n",
      "J. B. Lippincott Co.\n",
      "American Book Co.\n",
      "Macmillan & Co.\n",
      "Arena Company\n",
      "\n",
      "853770606\n",
      "Master House\n",
      "Master House\n",
      "\n",
      "137195890\n",
      "\n",
      "125727674\n",
      "\n",
      "88797650\n",
      "Wagnails Company\n",
      "Intensive Farming By Corbett New York Outing Publishing\n",
      "Science By Federigo Enriques Chicago Open Court Pubpishing Co\n",
      "Progressive Furnace Heating By Alfred King New York Sheet Metal Publishing\n",
      "Company\n",
      "Wagnails Company\n",
      "Intensive Farming By Corbett New York Outing Publishing Company\n",
      "Progressive Furnace Heating By Alfred King New York Sheet Metal Publishing Company\n",
      "\n",
      "89649761\n",
      "\n",
      "90967694\n",
      "\n",
      "89672866\n",
      "\n",
      "89674750\n",
      "New Shakespearean Society.\n",
      "E. P. Dutton & Co.\n",
      "Dodd, Mead & Co.\n",
      "E. P. Dutton & Co.\n",
      "Small, Maynard & Co.\n",
      "\n",
      "89635917\n",
      "\n",
      "124196531\n",
      "\n",
      "128176513\n",
      "New York Treat Co\n",
      "New York Treat Co\n",
      "New York Lea Brothers Co\n",
      "\n",
      "88477095\n",
      "125715359\n",
      "\n",
      "124189638\n",
      "\n",
      "136887509\n",
      "\n",
      "90554411\n",
      "\n",
      "90186165\n",
      "\n",
      "125502663\n",
      "A Group\n",
      "Browning Society\n",
      "\n",
      "125724646\n",
      "Bibliography. The Grafton Press\n",
      "\n",
      "124740955\n",
      "\n",
      "124707428\n",
      "89644579\n",
      "\n",
      "137072896\n",
      "House\n",
      "\n",
      "136685639\n",
      "Present. Biy T. T. Timayenis.JI. Appleton & Co.\n",
      "\n",
      "126788760\n",
      "\n",
      "89671107\n",
      "Riverside Press\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "    rev = ReviewObj(filename, txt)\n",
    "    print(filename)\n",
    "    if rev.person_names:\n",
    "        for x in rev.pub_names:\n",
    "            print(x)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Person Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = \"\"\"Doctor,Dr,Mr,Mrs,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Princess,Prince,Duke,Duchess,Baron,Father,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.rstrip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = '\\.?\\s(?=[A-Z])|'.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_not_following_title_or_initial(name):\n",
    "    name_parts = name.split()\n",
    "    cleaned_name = []\n",
    "    for part in name_parts:\n",
    "        if part[-1] in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~':\n",
    "            if (len(part)>2) and (part[:-1] not in titles):\n",
    "                cleaned_name.append(part[:-1])\n",
    "            else:\n",
    "                cleaned_name.append(part)\n",
    "        else:\n",
    "            cleaned_name.append(part)\n",
    "    return ' '.join(cleaned_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = remove_punct_not_following_title_or_initial(name)\n",
    "    cleaned_name = []\n",
    "    return ' '.join([word for word in name.split() if (word[0].isalpha())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCapitalizedWords(txt):\n",
    "    \"\"\"\n",
    "    Returns strings of capitalized words up 3 words long. \n",
    "    Removes words/phrases containing stopwords and words found later in the text lowercased.\n",
    "    \"\"\"\n",
    "    #listen idk why it won't just let me put in an optional repeat either\n",
    "    all_words = []\n",
    "    \n",
    "    #three words\n",
    "    all_words.extend([match for match in re.findall('[A-Z]\\S* [A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(remove_punct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(remove_punct(word).lower() not in txt) for word in match.split()])])\n",
    "    \n",
    "    #two words\n",
    "    two_words = [match for match in re.findall('[A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(remove_punct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(remove_punct(word).lower() not in txt) for word in match.split()])\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(two_words)\n",
    "    \n",
    "    #one word\n",
    "    one_words = [match for match in re.findall('[A-Z]\\S+', txt) if \n",
    "                      (remove_punct(match).lower() not in stopword_list) \n",
    "                      and (remove_punct(match).lower() not in txt)\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(one_words)\n",
    "    \n",
    "    return [word for word in [' '.join([removePunct(y) for y in x.split() if remove_punct(y) not in titles]) \n",
    "                      for x in all_words] if (len(word)>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidateNames(name_list):\n",
    "    \"\"\"\n",
    "    Takes list of AuthNames and returns list of lists, consolidating by likely identical authors.\n",
    "    \"\"\"\n",
    "    name_set = []\n",
    "    used_indices = []\n",
    "    last_names = sorted([name.last_name for name in name_list], key=len)\n",
    "    \n",
    "    for i, name in enumerate(last_names):\n",
    "        if i not in used_indices:\n",
    "            full_name = [x for x in name_list if x.last_name == name][0]\n",
    "            name_holder = [full_name]\n",
    "            for j, name2 in enumerate(last_names):\n",
    "                full_name2 = [x for x in name_list if x.last_name == name2][0]\n",
    "                if (i < (len(last_names) - 1)) and (i!=j):\n",
    "                    if (edit_distance(name, name2[:len(name)+1]) < 2) and (j not in used_indices):\n",
    "                        if (full_name.first_initial==full_name2.first_initial and full_name.middle_initial==full_name2.middle_initial or full_name.title==full_name2.title) or (full_name.first_initial==full_name2.first_initial or full_name.middle_initial==full_name2.middle_initial and full_name.title==full_name2.title):\n",
    "                            name_holder.append(full_name2)\n",
    "                            used_indices.append(j)\n",
    "            used_indices.append(i)\n",
    "            name_set.append(name_holder)\n",
    "    \n",
    "    return name_set                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_following_titles(review):\n",
    "    \"\"\"\n",
    "    Returns names following titles - specifically capitalized titles followed by capitalized names.\n",
    "    Names can be any number of words in length, and can include punctuation.\n",
    "    \n",
    "    \"\"\"\n",
    "    names = []\n",
    "    spans = []\n",
    "    \n",
    "    txt = review.cleaned_text\n",
    "\n",
    "    iterx = re.finditer(title_list, txt)\n",
    "    indices = [(m.start(), m.group()) for m in iterx]\n",
    "    \n",
    "    for e, index in enumerate(indices):\n",
    "        \n",
    "        if (e==len(indices)-1):\n",
    "            end_index = -1\n",
    "        else:\n",
    "            end_index = indices[e+1][0]\n",
    "        \n",
    "        end_span = len(txt[indices[e][0]:end_index])   \n",
    "        get_match = re.finditer('[A-Z]\\w+[^A-Z]|[A-Z].[^A-Z]', txt[indices[e][0]:end_index])\n",
    "        matches = [(m.span(), m.group()) for m in get_match]\n",
    "        matches.reverse()\n",
    "        \n",
    "        for n, m in enumerate(matches):\n",
    "            if n<len(matches)-1:\n",
    "                if (m[0][1] != matches[n-1][0][0]):\n",
    "                    end_span = m[0][1]\n",
    "        \n",
    "        result = txt[indices[e][0]:(indices[e][0] + end_span - 1)]\n",
    "        \n",
    "        if len(result) > len(indices[e][1]):\n",
    "            names.append(txt[indices[e][0]:(indices[e][0] + end_span - 1)])\n",
    "            spans.append(indices[e][0])\n",
    "        \n",
    "    names = [word.replace(\"'s\", \"\") for word in names]\n",
    "    names = [PersonName(clean_name(word)) for word in names]\n",
    "    \n",
    "    for e, name in enumerate(names):\n",
    "        name.review_id = review.review_id\n",
    "        name.review_loc = (spans[e], spans[e]+len(name))\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReviewObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewObj():\n",
    "    \n",
    "    def __findnames(self):\n",
    "        self.pub_names = get_publishers(self)\n",
    "        self.person_names = get_names_following_titles(self)\n",
    "        \n",
    "    def __init__(self, aps_id, txt):\n",
    "        self.review_id = aps_id\n",
    "        self.original_text = txt\n",
    "        self.cleaned_text = preprocess_text(txt)\n",
    "        \n",
    "        self.__findnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_ex = ReviewObj(136726613, txts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Charles Dudley Warner\n",
      "Mr. Vedder\n",
      "Professor Thorold Rogers\n",
      "Mrs. Browning\n",
      "Mr. Swinburne\n",
      "Dr. William\n",
      "Dr. Geor6 Ebers\n",
      "Mr. Julian Hawthorne\n",
      "Mr. Julius Chambers\n",
      "Mr. Cushing\n",
      "Dr. Herbert B. Adam\n",
      "President Andrew D. White\n",
      "Mr. Brander Matthews\n",
      "Dr. Joseph Parktercontinueshiseipositionuin\n",
      "Professor E. Johnsou\n",
      "Dr. Malaren\n",
      "Dr. Parker\n"
     ]
    }
   ],
   "source": [
    "for x in review_ex.person_names:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136726613\n",
      "Mr. Charles Dudley Warner\n",
      "Mr. Vedder\n",
      "Professor Thorold Rogers\n",
      "Mrs. Browning\n",
      "Mr. Swinburne\n",
      "Dr. William\n",
      "Dr. Geor6 Ebers\n",
      "Mr. Julian Hawthorne\n",
      "Mr. Julius Chambers\n",
      "Mr. Cushing\n",
      "Dr. Herbert B. Adam\n",
      "President Andrew D. White\n",
      "Mr. Brander Matthews\n",
      "Dr. Joseph Parktercontinueshiseipositionuin\n",
      "Professor E. Johnsou\n",
      "Dr. Malaren\n",
      "Dr. Parker\n",
      "\n",
      "90142613\n",
      "Mr. E. L. Voynich\n",
      "\n",
      "90390665\n",
      "Miss HowAiD\n",
      "Mrs. A. L. Wister\n",
      "Princess Mercedes\n",
      "Miss Peard\n",
      "Miss Peard\n",
      "Lord Mttdhursm\n",
      "Miss Peard\n",
      "Sir Henry Lancaster\n",
      "\n",
      "124486140\n",
      "Dr. Atwood\n",
      "\n",
      "126315326\n",
      "136992742\n",
      "137651039\n",
      "Lord Clive\n",
      "Mr. Alden\n",
      "Mr. Bixby\n",
      "Mr. Crane\n",
      "Mr. Cook\n",
      "Mr. Cook\n",
      "Prof. Tillman\n",
      "Mr. Thomas A. Edison\n",
      "Mr. Tompkins\n",
      "Mr. Haggard\n",
      "Mr. Arthur Gillman\n",
      "Mr. Gillman\n",
      "Dr. Brown-Sequard\n",
      "Dr. Brown-Sequard\n",
      "Dr. Variot\n",
      "\n",
      "89668273\n",
      "Mr. Kenneth Grahame\n",
      "Mr. Maxfield Parrish\n",
      "Mr. Parrish\n",
      "Mr. Swinburne\n",
      "Mr. Arthur Symons\n",
      "Mr. Havelock Ellis\n",
      "Mr. A. Wilson Verity\n",
      "Mr. George Saintsbury\n",
      "\n",
      "136971619\n",
      "90313218\n",
      "Mr. Cabot Lodge\n",
      "Mr. Adams\n",
      "Mr. Morse\n",
      "Mr. Oallatir\n",
      "Mr. Htevens\n",
      "Mr. Lodge\n",
      "Mr. Gallatin\n",
      "Mr. Gailatin\n",
      "Mr. Stevens\n",
      "Mr. Clallatiiis\n",
      "Mr. Jefferson\n",
      "Mr. Qallathi\n",
      "\n",
      "128376070\n",
      "Mr Heyny\n",
      "\n",
      "124688361\n",
      "124882533\n",
      "Mr. Rees\n",
      "Mr. Rees\n",
      "Mr. Ralph\n",
      "Miss Serjeant\n",
      "Mr. Rees\n",
      "Mr. Rees\n",
      "Mr. Rees\n",
      "Mr. Dawe\n",
      "Mr. Dawe\n",
      "Mr. Dawe\n",
      "\n",
      "89639059\n",
      "Mr. Ilowolls\n",
      "Mr. Kegan Paul\n",
      "\n",
      "88461015\n",
      "Mrs Francis Reeves\n",
      "Dr Reeves\n",
      "Dr Reeve\n",
      "\n",
      "124190789\n",
      "Sir Christopher\n",
      "Sir Christopher\n",
      "Mrs. Goodwin\n",
      "Mr. James\n",
      "Mrs. Wharton\n",
      "\n",
      "136902134\n",
      "Dr. Paul Sollier\n",
      "Dr. Rubens Hirschber\n",
      "\n",
      "90180084\n",
      "Mr. John C. Van Dyke\n",
      "Mr. Van Dyke\n",
      "Mr. Chase\n",
      "Mr. Hamilton W. Mabie\n",
      "Mr. Mabie\n",
      "Mr. Mabie\n",
      "Miss Mary Thorn Carpenter\n",
      "Miss Carpenter\n",
      "Miss Carpenter\n",
      "Mr. W. H. Hadow\n",
      "Mr. Hadow\n",
      "Mr. Hadow\n",
      "\n",
      "137244878\n",
      "Mrs. Wharton\n",
      "Mrs. Schuyler Van Rensselaer\n",
      "President Lowell\n",
      "Mr. Vachel Lindsay\n",
      "Mr. Kipling\n",
      "\n",
      "88721263\n",
      "137412078\n",
      "Professor Brastow\n",
      "\n",
      "89675095\n",
      "Mr. William Butler Yeats\n",
      "Mr. Nicholas Vachel Lindsay\n",
      "Mr. Lindsay\n",
      "Mr. Lindsay\n",
      "Mrs. Billious\n",
      "Mr. Billious\n",
      "Director of the American School\n",
      "\n",
      "760950213\n",
      "124217248\n",
      "Mr. Richard Hovey\n",
      "Mr. Hovey\n",
      "Prince Henry\n",
      "Prince Henry\n",
      "Mr. Beazley\n",
      "Prof. E. D. Perry\n",
      "Prof. Friedrich Paulsen\n",
      "Prof. N. M. Butler\n",
      "Professor Patulsen\n",
      "Professor Butler\n",
      "Prof. A.\n",
      "Dr. William Pepper\n",
      "Miss Edgeworth\n",
      "Dr. C. E. Stevens\n",
      "Dr. F. S. Billings\n",
      "\n",
      "853770606\n",
      "Master House Painters\n",
      "Master House Painters\n",
      "\n",
      "137195890\n",
      "Miss Curtis\n",
      "Miss Curtis\n",
      "Miss Cultis\n",
      "Mr. Kimhleni\n",
      "Mr. Fordher\n",
      "Mr. Kiiiiein\n",
      "Miss Curtis\n",
      "\n",
      "125727674\n",
      "Dr. Alfred Hirchhoffund\n",
      "Dr. Willi Ule\n",
      "\n",
      "88797650\n",
      "Professor Josiah Royce\n",
      "\n",
      "89649761\n",
      "Professor Hiram Corson\n",
      "Professor Corson\n",
      "Professor Corson\n",
      "\n",
      "90967694\n",
      "President Garfield\n",
      "President Cleveland\n",
      "\n",
      "89672866\n",
      "Professor Lane Cooper\n",
      "Professor Cooper\n",
      "Mr. Edward Carpenter\n",
      "Mr. Edward Lewis\n",
      "Mr. Lewis\n",
      "Professor Bergson\n",
      "\n",
      "89674750\n",
      "Mr. Harry Thurston Peck\n",
      "Professor Peck\n",
      "Professor Peck\n",
      "Professor Peck\n",
      "Professor Peck\n",
      "Dr. Charles F. Johnson\n",
      "Professor Johnson\n",
      "Professor Johnson\n",
      "Dr. J. B. Bury\n",
      "Professor Bury\n",
      "Professor Bury\n",
      "Mr. Gardiner M. Lane\n",
      "Professor Bury\n",
      "Mrs. Stowe\n",
      "Mrs. Brown\n",
      "Rev. P. H. Ditchfield\n",
      "Dr. South\n",
      "Mr. Winthrop Packard\n",
      "\n",
      "89635917\n",
      "Mr. Arnold\n",
      "\n",
      "124196531\n",
      "Mr. G. W. E. Russell\n",
      "Lord Shaftesbury\n",
      "Lord Houghton\n",
      "Lord Beaconsfield\n",
      "Lord Beaconsfield\n",
      "Mr. Gladstone\n",
      "Professor Moses Colt Tyler\n",
      "\n",
      "128176513\n",
      "Dr Heitzmann\n",
      "Dr Heitzmann\n",
      "Dr Heitzmann\n",
      "Dr Heitzmann\n",
      "Dr Heitzmann\n",
      "Sir William Roberts\n",
      "Dr Heitzmann\n",
      "Dr Heitzmann\n",
      "\n",
      "88477095\n",
      "125715359\n",
      "Mr. Mill\n",
      "Dr. Campbell\n",
      "\n",
      "124189638\n",
      "Dr. Peroy Gardner\n",
      "Master In\n",
      "Mr. Gardner\n",
      "Dr. Gardner\n",
      "\n",
      "136887509\n",
      "Dr. Bramwell\n",
      "Mr. Herbert Page\n",
      "\n",
      "90554411\n",
      "Mr. Yeats\n",
      "Mr. Yeats\n",
      "\n",
      "90186165\n",
      "Prof. Fisher\n",
      "Prof. Fisher\n",
      "Dr. Fisher\n",
      "\n",
      "125502663\n",
      "Mr. Matthew Arnold\n",
      "Dr. Farrar\n",
      "Dean Farrar\n",
      "Lord Beaconsfield\n",
      "Dr. Farrar\n",
      "Dean Stanley\n",
      "Dr. Farrar\n",
      "Dean Farrar\n",
      "Dean Farrar\n",
      "Dr. Short\n",
      "Dean Farrar\n",
      "Dean Farra\n",
      "\n",
      "125724646\n",
      "Sir Alfred Lyall\n",
      "Dr. W. Koppen\n",
      "Dr. Lemoine\n",
      "Dr. Lemoine\n",
      "Dr. Lemoine\n",
      "Dr. Lemoine\n",
      "Mr. Garnett\n",
      "Dr. Waither\n",
      "\n",
      "124740955\n",
      "Mrs. Brathers\n",
      "Mr. Jewell\n",
      "\n",
      "124707428\n",
      "89644579\n",
      "Miss Georgiana Hill\n",
      "\n",
      "137072896\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "President Buchanan\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "President Lincoln\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Mrs. Livermore\n",
      "Mrs. Stanton\n",
      "Miss Barton\n",
      "Dr. HIenry Bellows\n",
      "Miss Barton\n",
      "President Hayes\n",
      "President Moynier\n",
      "President Garfield\n",
      "Miss Barton\n",
      "President Arthur\n",
      "President Moynier\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Barton\n",
      "Miss Anthony\n",
      "Miss Barton\n",
      "\n",
      "136685639\n",
      "Mr. Symonds\n",
      "Mr. Timayenis\n",
      "Mr. Timayenis\n",
      "Mr. Timayenis\n",
      "Mr. Timayenis\n",
      "\n",
      "126788760\n",
      "Mr. Tennnnttheeditor\n",
      "\n",
      "89671107\n",
      "Mr. Murdock\n",
      "Mr Austin Dobson\n",
      "Mr. Murdock\n",
      "Mrs. Boscawen\n",
      "Lady Sarah Bunbury\n",
      "Dr. Cauer\n",
      "Reverend Mather Byles\n",
      "Lord Percy\n",
      "Doctor Byles\n",
      "Dr. Byles\n",
      "Dr. Goldsmith\n",
      "Dr. Byles\n",
      "Mr. Pope\n",
      "Lord Holland\n",
      "Lord Hollanid\n",
      "Mr. Murdock\n",
      "Mr. Stuart\n",
      "Mr. Vassall\n",
      "Mr. Murdock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename, txt in zip([x.split('.')[0] for x in filenames],txts):\n",
    "    rev = ReviewObj(filename, txt)\n",
    "    print(filename)\n",
    "    if rev.person_names:\n",
    "        for x in rev.person_names:\n",
    "            print(x)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in review_ex.person_names:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy NLP object steal their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt, filename in zip(txts, [x.split('.')[0] for x in filenames]):\n",
    "    print(filename)\n",
    "    docnames = get_names_following_titles(txt, filename)\n",
    "    for name in docnames:\n",
    "        print(name, name.review_loc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "Make each Person name aware of others and able to check for potential matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
