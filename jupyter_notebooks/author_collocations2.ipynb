{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from application.review_obj_class import ReviewObj\n",
    "# from application.namespan_class import NameSpanGenerator\n",
    "# import pandas as pd\n",
    "# %pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../aps_reviews_1000/\"\n",
    "filenames = os.listdir(directory)\n",
    "reviews = ((file.split('.')[0], open(directory + file).read()) for file in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = [ReviewObj(file, txt) for (file, txt) in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = NameSpanGenerator.generate(review_list[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',', 'by', 'Professor_Leo_Wiener', 'of', 'Harvard'], [',', 'thinks', 'Professor_Wiener', ',', 'that']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.collocates for x in ex.spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Charles', 'the', 'I', 'Swedish', 'Colaprde', 'Aned', 'Xll', 'of']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set((x for x in review_list[0].cleaned_text[:50].split() if x.isalnum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Professor Leo Wiener, Professor Wiener]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.name for x in ex.spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in review_list:\n",
    "    x = NameSpanGenerator.generate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_reviews = [x for x in review_list if (len(x.person_names) > 3) and (len(x.pub_names) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr. Leopold Damrosch, Mr. Andrew Carnegie, Dr. LeopOld Damrosch, Prof. Horatio W. Parker, Mr. Parker, Lord. The, Oratorio Society, Oratorio Society, Mendelssohn Society, Symphony Society]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.name for x in example_reviews[0].spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_indices = [x.name.review_loc_toks for x in example_reviews[0].spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[244, 423, 459, 493, 561, 731, 3, 64, 284, 433]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z873', 'that', 'Dr._Leopold_Damrosch', 'united', 'a']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_reviews[0].coll_toks_ind[name_indices[0]-2:name_indices[0]+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concord_spans(ReviewObj):\n",
    "    ni = [x.name.review_loc_toks for x in ReviewObj.spans]\n",
    "    for e, span in enumerate(ReviewObj.spans):\n",
    "        span.collocates = ReviewObj.coll_toks_ind[ni[e]-2:ni[e]+3]\n",
    "    return ReviewObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = concord_spans(example_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z873', 'that', 'Dr._Leopold_Damrosch', 'united', 'a']\n",
      "['president', 'is', 'Mr._Andrew_Carnegie', '.', 'to']\n",
      "['chief', 'matters', 'Dr._LeopOld_Damrosch', \"'s\", 'pretty']\n",
      "['oratorio', 'by', 'Prof._Horatio_W._Parker', ',', 'of']\n",
      "['As', 'to', 'Mr._Parker', \"'s\", 'fine']\n",
      "['Christ', 'the', 'Lord._The', 'simple', 'story']\n",
      "['.', 'The', 'Oratorio_Society', \"'s\", 'Jubilee']\n",
      "['.', 'The', 'Oratorio_Society', 'of', 'New']\n",
      "[',', 'the', 'Mendelssohn_Society', ',', 'the']\n",
      "['does', 'the', 'Symphony_Society', ',', 'an']\n"
     ]
    }
   ],
   "source": [
    "for span in ex.spans:\n",
    "    print(span.collocates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief aside: trying to make stuff load faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peeps = ((s.name for s in x.spans if s.label=='person') for x in review_list if x.person_names)\n",
    "# pubs = ((s.name for s in x.spans if s.label=='publisher') for x in review_list if x.person_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_people_list = [n for rev in peeps for n in rev]\n",
    "# big_pubs_list = [n for rev in pubs for n in rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [open(directory + file).read() for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from application.name_obj_classes import PubName, PersonName, remove_punct\n",
    "from application.text_preprocessing import preprocess_text\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import pickle\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "\n",
    "pub_ends = ['company','co','incorporated','inc','firm','press','group','publishers','publishing',\n",
    "                    'publications','pub','books','ltd','limited','society','house','associates']\n",
    "pub_ends = [x.capitalize() for x in pub_ends]\n",
    "\n",
    "city_dict = pickle.load(open('../data/city_dict.pkl', 'rb'))\n",
    "\n",
    "def is_part_of_pub(pub_part):\n",
    "    if (pub_part == 'and') or (pub_part =='&'):\n",
    "        return True\n",
    "    elif city_dict.lookup(pub_part.lower(), Verbosity.CLOSEST, max_edit_distance=2):\n",
    "        return False\n",
    "    else:\n",
    "        return pub_part[0].isupper()\n",
    "\n",
    "def obscure_single_match(text, x, y):\n",
    "    text_list = list(text)\n",
    "    text_list[x:y] = list(len(text[x:y]) * '@')\n",
    "    return ''.join(text_list)\n",
    "\n",
    "def remove_duplicate_pubnames(pnlist):\n",
    "    cleaned = []\n",
    "    for e, (x, y) in enumerate(pnlist):\n",
    "        starts = [a for (a,b) in pnlist[e+1:]]\n",
    "        if x in starts:\n",
    "            pass\n",
    "        else:\n",
    "            cleaned.append(pnlist[e])\n",
    "    return cleaned\n",
    "\n",
    "def get_publishers(review):\n",
    "    \"\"\"\n",
    "    Takes a ReviewObj.\n",
    "    Returns a list of potential publishers. Searches using pub_ends, capitalization, and associates.\n",
    "\n",
    "    For reference:\n",
    "    -------------\n",
    "    pub_ends = ['co','company','inc','incorporated','firm','press','group', 'pub','publishers','publishing',\n",
    "                    'publications','books','ltd','limited','society','house','associates']\n",
    "\n",
    "    pub_associates = ['sons','son','brother','brothers']\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pubs = []\n",
    "    char_spans = []\n",
    "    tok_spans = []\n",
    "\n",
    "    toks = review.cleaned_toks\n",
    "    txt = review.cleaned_text\n",
    "\n",
    "    pubnames = []\n",
    "\n",
    "    for e, tok in enumerate(toks):\n",
    "        if tok.replace(\",\",\"\").replace(\".\",\"\") in pub_ends:\n",
    "            if is_part_of_pub(toks[e-1]):\n",
    "                pub_name = []\n",
    "                pub_span = []\n",
    "                for pos in range(e-1, e-6, -1):\n",
    "                    if toks[pos] == '.':\n",
    "                        break\n",
    "                    if toks[pos] in pub_ends:\n",
    "                        break\n",
    "                    if not is_part_of_pub(toks[pos]):\n",
    "                        break\n",
    "                    pub_name.append(toks[pos])\n",
    "                    pub_span.append(pos)\n",
    "                if any([x.isalpha() for x in [word for word in pub_name if word !='and']]) and any([len(x)>2 for x in [word for word in pub_name if word !='and']]):\n",
    "                    pubnames.append((pub_span[-1], e+1))\n",
    "\n",
    "    pubnames = remove_duplicate_pubnames(pubnames)\n",
    "\n",
    "    if len(pubnames) > 0:\n",
    "        temp_txt = txt\n",
    "        for (x, y) in pubnames:\n",
    "            newname = ' '.join(toks[x:y])\n",
    "            pubs.append(newname)\n",
    "            tok_spans.append((x,y))\n",
    "            match = re.search(newname, temp_txt)\n",
    "            char_spans.append(match.span())\n",
    "            temp_txt = obscure_single_match(temp_txt, *match.span())\n",
    "\n",
    "    pubs = [PubName(word) for word in pubs]\n",
    "\n",
    "    for e, pub in enumerate(pubs):\n",
    "        pub.review_id = review.review_id\n",
    "        pub.review_loc_toks = tok_spans[e]\n",
    "        pub.review_loc_chars = char_spans[e]\n",
    "\n",
    "    return pubs\n",
    "\n",
    "titles = \"\"\"Doctor,Dr,Mr,Mrs,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Princess,Prince,Duke,Duchess,Baron,Father,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\n",
    "\"\"\"\n",
    "titles = titles.rstrip().split(',')\n",
    "title_list = '\\.?\\s(?=[A-Z])|'.join(titles) + '\\.?\\s(?=[A-Z])'\n",
    "\n",
    "def remove_punct_not_following_title_or_initial(name):\n",
    "    name_parts = name.split()\n",
    "    cleaned_name = []\n",
    "    for part in name_parts:\n",
    "        if part[-1] in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~':\n",
    "            if (len(part)>2) and (part[:-1] not in titles):\n",
    "                cleaned_name.append(part[:-1])\n",
    "            else:\n",
    "                cleaned_name.append(part)\n",
    "        else:\n",
    "            cleaned_name.append(part)\n",
    "    return ' '.join(cleaned_name)\n",
    "\n",
    "def clean_name(name):\n",
    "    name = remove_punct_not_following_title_or_initial(name)\n",
    "    cleaned_name = []\n",
    "    return ' '.join([word for word in name.split() if (word[0].isalpha())])\n",
    "\n",
    "def get_names_following_titles(review):\n",
    "    \"\"\"\n",
    "    Returns names following titles - specifically capitalized titles followed by capitalized names.\n",
    "    Names can be any number of words in length, and can include punctuation.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    spans = []\n",
    "\n",
    "    txt = review.no_pubs_text\n",
    "\n",
    "    iterx = re.finditer(title_list, txt)\n",
    "    indices = [(m.start(), m.group()) for m in iterx]\n",
    "\n",
    "    for e, index in enumerate(indices):\n",
    "\n",
    "        if (e==len(indices)-1):\n",
    "            end_index = -1\n",
    "        else:\n",
    "            end_index = indices[e+1][0]\n",
    "\n",
    "        end_span = len(txt[indices[e][0]:end_index])\n",
    "        get_match = re.finditer('[A-Z]\\w+[^A-Z]|[A-Z].[^A-Z]', txt[indices[e][0]:end_index])\n",
    "        matches = [(m.span(), m.group()) for m in get_match]\n",
    "        matches.reverse()\n",
    "\n",
    "        for n, m in enumerate(matches):\n",
    "            if n<len(matches)-1:\n",
    "                if (m[0][1] != matches[n-1][0][0]):\n",
    "                    end_span = m[0][1]\n",
    "\n",
    "        result = txt[indices[e][0]:(indices[e][0] + end_span - 1)]\n",
    "\n",
    "        if len(result) > len(indices[e][1]):\n",
    "            names.append(txt[indices[e][0]:(indices[e][0] + end_span - 1)])\n",
    "            spans.append(indices[e][0])\n",
    "\n",
    "    names = [word.replace(\"'s\", \"\") for word in names]\n",
    "    names = [PersonName(clean_name(word)) for word in names]\n",
    "\n",
    "    for e, name in enumerate(names):\n",
    "        name.review_id = review.review_id\n",
    "        name.review_loc_chars = (spans[e], spans[e]+len(name))\n",
    "\n",
    "    return names\n",
    "\n",
    "class ReviewObj():\n",
    "    \"\"\"\n",
    "    Object type for book reviews.\n",
    "    Takes aps_id followed by review text. Both are required.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self.review_id : aps_id\n",
    "    self.original_text : text passed to the original init\n",
    "    self.cleaned_text : cleaned text for generating names\n",
    "    self.pub_names : list of PubNames contained within the review\n",
    "    self.person_names : list of PersonNames contained within the review\n",
    "    self.cleaned_toks : cleaned_text tokenized using NLTK word_tokenize\n",
    "    self.coll_toks_ind : tokens but all spaces in NameObjs replaced by underscores\n",
    "    self.coll_toks_all : tokens but PubNames, PersonNames replaced by ■,●\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __obscure_matches(self, name = 'ex'):\n",
    "        text_list = list(self.cleaned_text)\n",
    "        if name == 'pub':\n",
    "            for (x, y) in [pub.review_loc_chars for pub in self.pub_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "        if name == 'person':\n",
    "            for (x, y) in [pers.review_loc_chars for pers in self.person_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '@')\n",
    "        if name == 'both':\n",
    "            for (x, y) in [pub.review_loc_chars for pub in self.pub_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '■')\n",
    "            for (x, y) in [pers.review_loc_chars for pers in self.person_names]:\n",
    "                text_list[x:y] = list(len(self.cleaned_text[x:y]) * '●')\n",
    "        return ''.join(text_list)\n",
    "\n",
    "    def __prep_for_collocations(self):\n",
    "        text_list = list(self.cleaned_text)\n",
    "        for (x, y) in [pub.review_loc_chars for pub in self.pub_names]:\n",
    "            text_list[x:y] = list(self.cleaned_text[x:y].replace(' ','_'))\n",
    "        for (x, y) in [pers.review_loc_chars for pers in self.person_names]:\n",
    "            text_list[x:y] = list(self.cleaned_text[x:y].replace(' ','_'))\n",
    "        return ''.join(text_list)\n",
    "\n",
    "    def __get_tok(self):\n",
    "        pub_toks = [e for e, x in enumerate(self.coll_toks_all) if \"■\" in x]\n",
    "        pers_toks = [e for e, x in enumerate(self.coll_toks_all) if \"●\" in x]\n",
    "        for e, pub in enumerate(self.pub_names):\n",
    "            pub.review_loc_toks = pub_toks[e]\n",
    "        for e, pers in enumerate(self.person_names):\n",
    "            pers.review_loc_toks = pers_toks[e]\n",
    "\n",
    "    def __findnames(self):\n",
    "        self.pub_names = get_publishers(self)\n",
    "        self.no_pubs_text = self.__obscure_matches(name = 'pub')\n",
    "        self.person_names = get_names_following_titles(self)\n",
    "        self.no_people_text = self.__obscure_matches(name = 'person')\n",
    "        self.spans = ''\n",
    "\n",
    "    def __init__(self, aps_id, txt):\n",
    "        self.review_id = aps_id\n",
    "        self.original_text = txt\n",
    "        self.cleaned_text = preprocess_text(txt)\n",
    "        self.cleaned_toks = word_tokenize(self.cleaned_text)\n",
    "\n",
    "        self.__findnames()\n",
    "\n",
    "        self.coll_toks_ind = word_tokenize(self.__prep_for_collocations())\n",
    "        self.coll_toks_all = word_tokenize(self.__obscure_matches(name = 'both'))\n",
    "\n",
    "        self.__get_tok()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current status: 37 seconds to create ReviewObjs out of all 1003 reviews\n",
    "That's fine. But it could be much faster. Also I keep redoing it and it gets slower somehow. Idk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = zip(filenames, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
