{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding names in book reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.metrics import edit_distance\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in files\n",
    "directory = \"../../aps_reviews_50/aps_reviews/\"\n",
    "filenames = os.listdir(directory)\n",
    "txts = []\n",
    "for file in filenames:\n",
    "    with open(directory + file) as f:\n",
    "        txts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pickle.load(open('author_title_df.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_by_last_name = pickle.load(open('author_last_name_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find names using titles and capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = \"\"\"Doctor,Dr,Mr,Mrs,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.rstrip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_list = r\"\\.? .+? |\".join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = '.?\\s|'.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test text\n",
    "mytext = \"\"\"\n",
    "    Missouri: A Bone of Contention '                 WE  aware that most of the States of the Union had their nicknames, more or less complimentary, but to name Missouri ' a bone of contention ' is a stroke of wit. It does, however, rightly describe the Missouri of the past, and vividly writes in a phrase her political history. Until the triumph of the Union armies and the close of the Civil War, Missouri was in the jaws of the watch-dogs of slavery and freedom. In war or in peace, the subiect of legislative com-                 promise or of military struggle, Missouri was an uncertain factor. Now, after -five years of national peace, her history may be calmly and impartially written. Indeed, the task has been done, and well done, and the , Lucien Carr of Harvard, may be congratulated upon his work,  is strong, unimpassioned, scholarly, and as impressed with the firm touch which comes of local knowledge as are the imprinted rocks in the cabinets at Cambridge. Long familiarity with the wealth of archaeology in the Peabody Museuml seems to have given him the power of comparison and generalization in the evolution of a commonwealth, while  acquaintance with living men enables him to blend the results of the study and the field in pleasing literary form. Five of his seventeen chapters give a luminous picture of the early French and Spanish discoveries and domination. Then follow three chapters treating of the                 Missouri. By Ldclen Carr. $ti... (American Commonwealths.) Boston:                 Itoughto., Sftfltn & Co.                 l , the compromise, and the  into the U nion of this State named after the great river which flows through it. In his treatment of the period from 1844 to i861, as well as that of war time, some readers may charge Mr. Carr with unduly favoring the Southern and even Confederate view; but to people living this side of the now-vanished Mason and Dixon's line, this is doubtless a benefit; for only when Northern people are able to ' put themselves in the place' of Southerners and see with Southern eyes, can they be sure that they have achieved that impartiality which is essential to the writing of final history. He shows that the Missourians were neither secessionists nor slavery propagandists. He both criticises and justifies the action of the second convention which, in the uncertain hours when other States  seceding and Missouri's Governor had been driven into exile, org  a provisional government, and  saved Missouri Irons ' the pit of political degradation into which the States in rebellion were sunk during the period of reconstruction.' Mr. Carr practically and almost abruptly ends his history at the close of the War, believing that the career of Missouri as a bone of contention ended with the abolition of slavery. The fifty years' struggle was over, the State recovered rapidly froni the wounds of the Civil War, wealth increased wonderfully, and the Negro was liberally dealt with in most if not all points relating to citizenship. Taken as a whole, this book, with its sustained interest, high average literary merit, and thorough treatment of the voluminous facts, fully justifies its place in the series of ' histories of such States as have exercised a positive influence in the shaping of the national Government, or have had a striking political - . . history.' Like the others, it has a good map and index.\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity \n",
    "\n",
    "# maximum edit distance per dictionary precalculation\n",
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "# create object\n",
    "first_name_symspell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "# load dictionary\n",
    "dictionary_path = \"name_freq_dict.txt\"\n",
    "term_index = 0 \n",
    "count_index = 1\n",
    "first_name_symspell.load_dictionary(dictionary_path, term_index, count_index, separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_last_name_list = ','.join(list(authors_by_last_name.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"authors_last_name_list.txt\", \"w\")\n",
    "f.write(authors_last_name_list)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum edit distance per dictionary precalculation\n",
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "# create object\n",
    "author_surname_symspell = SymSpell()\n",
    "# load dictionary\n",
    "term_index = 0 \n",
    "count_index = 1\n",
    "author_surname_symspell.create_dictionary('authors_last_name_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTextForNameSearch(txt):\n",
    "    \"\"\"\n",
    "    Removes all non-newline whitespace and adds spaces around commas, semicolons, and colons.\n",
    "    \"\"\"\n",
    "    #delete extra whitespace\n",
    "    txt = re.sub(' +',' ',txt)\n",
    "    \n",
    "    #delete characters that should never be in this dataset (i think)\n",
    "    txt = re.sub(\"\\\\'\\(\\)\\*/<=>@\\[\\]^_`\\|~\",\"\",txt)\n",
    "    \n",
    "    #adding space around certain punctuation\n",
    "    txt = re.sub(',',' , ',txt)\n",
    "    txt = re.sub(';',' ; ',txt)\n",
    "    txt = re.sub(':',' : ',txt)\n",
    "    txt = re.sub('\"',' \" ',txt)\n",
    "    txt = re.sub(\"'\",\" ' \" ,txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "+ reduce names down to 1880-1900\n",
    "+ rule for 's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePeriodsNotFollowingTitleOrInitial(name):\n",
    "    name_parts = name.split()\n",
    "    cleaned_name = []\n",
    "    for part in name_parts:\n",
    "        if (len(part)>2) and (part.endswith('.')) and (part[:-1] not in titles):\n",
    "            cleaned_name.append(part[:-1])\n",
    "        else:\n",
    "            cleaned_name.append(part)\n",
    "    return ' '.join(cleaned_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanIndices(index_tuple):\n",
    "    x = index_tuple[0]\n",
    "    y = index_tuple[1]\n",
    "    if y[-1] in '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~':\n",
    "        y = y[:-1]\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isName(name):\n",
    "    return len([word for word in name.split() if word[0].isupper()])>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNamesFollowingTitles(txt):\n",
    "    \"\"\"\n",
    "    Returns names following titles - specifically capitalized titles followed by capitalized names.\n",
    "    Names can be any number of words in length, and can include punctuation.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    \n",
    "    # iter only works once before emptying\n",
    "    iterx = re.finditer(title_list, txt)\n",
    "    indices = [(m.start(), m.group()) for m in iterx]\n",
    "    indices = [cleanIndices(m) for m in indices]\n",
    "    \n",
    "    for i, index in enumerate(indices):\n",
    "        if (i<len(indices)-1):\n",
    "            try:\n",
    "                match = re.match(indices[i][1] + '\\w{2,}[.,;:!\\?\\'\\\"]', txt[indices[i][0]:indices[i+1][0]])\n",
    "                names.append(match.group()[:-1])\n",
    "            except:\n",
    "                try:\n",
    "                    match = re.match(indices[i][1] + '.*? [\\\\\\/\\?!\\'\\\"]', txt[indices[i][0]:indices[i+1][0]])\n",
    "                    names.append(match.group()[:-1])\n",
    "                except:\n",
    "                    try:\n",
    "                        match = re.match(indices[i][1] + '.*? [a-z]|\\Z', txt[indices[i][0]:indices[i+1][0]])\n",
    "                        names.append(match.group()[:-2])\n",
    "                    except:\n",
    "                        pass\n",
    "        else:\n",
    "            try:\n",
    "                match = re.match(indices[i][1] + '\\w{2,}[.,;:!\\?\\'\\\"]', txt[indices[i][0]:])\n",
    "                names.append(match.group()[:-1])\n",
    "            except:\n",
    "                try:\n",
    "                    match = re.match(indices[i][1] + '.*? [a-z]|\\Z', txt[indices[i][0]:])\n",
    "                    names.append(match.group()[:-2])\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    names = [word.replace(\"'s\", \"\") for word in names]\n",
    "    names = [removePeriodsNotFollowingTitleOrInitial(word) for word in names]\n",
    "    names = [word for word in names if isName(word)]\n",
    "    \n",
    "    return list(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunct(word):\n",
    "    return ''.join([x for x in word if (x.isalpha()) or (x == '-') or (x=='â€“')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCapitalizedWords(txt):\n",
    "    \"\"\"\n",
    "    Returns strings of capitalized words up 3 words long. \n",
    "    Removes words/phrases containing stopwords and words found later in the text lowercased.\n",
    "    \"\"\"\n",
    "    #listen idk why it won't just let me put in an optional repeat either\n",
    "    all_words = []\n",
    "    \n",
    "    #three words\n",
    "    all_words.extend([match for match in re.findall('[A-Z]\\S* [A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(removePunct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(removePunct(word).lower() not in txt) for word in match.split()])])\n",
    "    \n",
    "    #two words\n",
    "    two_words = [match for match in re.findall('[A-Z]\\S* [A-Z]\\S+', txt) if \n",
    "                      all([(removePunct(word).lower() not in stopword_list) for word in match.split()]) \n",
    "                      and all([(removePunct(word).lower() not in txt) for word in match.split()])\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(two_words)\n",
    "    \n",
    "    #one word\n",
    "    one_words = [match for match in re.findall('[A-Z]\\S+', txt) if \n",
    "                      (removePunct(match).lower() not in stopword_list) \n",
    "                      and (removePunct(match).lower() not in txt)\n",
    "                      and all([match not in x for x in all_words])]\n",
    "    \n",
    "    all_words.extend(one_words)\n",
    "    \n",
    "    return [word for word in [' '.join([removePunct(y) for y in x.split() if removePunct(y) not in titles]) \n",
    "                      for x in all_words] if (len(word)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_distance('voynich','voynicch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getNamesFollowingTitles(cleanTextForNameSearch(txts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'President Andrew D. White'\n",
    "y = 'Lord is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([word for word in y.split() if word[0].isupper()])>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetOfNames(txt):\n",
    "    \"\"\"\n",
    "    Returns sets of names matched by similarity.\n",
    "    \"\"\"\n",
    "    all_name_sets = []\n",
    "    \n",
    "    known_names = getNamesFollowingTitles(txt)\n",
    "    potential_names = getCapitalizedWords(txt)\n",
    "    \n",
    "    for known in known_names:\n",
    "        name_set = []\n",
    "        name_set.append(known)\n",
    "        name_parts = [removePunct(x).lower() for x in known.split() if removePunct(x) not in titles]\n",
    "        \n",
    "        try:\n",
    "            author_surname_symspell._words[name_parts[-1].lower()]\n",
    "            for n in potential_names:\n",
    "                lookup = author_surname_symspell.lookup(n.lower(), Verbosity.CLOSEST)\n",
    "                if (lookup):\n",
    "                    for i, x in enumerate(lookup):\n",
    "                        if (lookup[i]._term in name_parts):\n",
    "                            name_set.append(n)\n",
    "        \n",
    "        except:\n",
    "            for n in potential_names:\n",
    "                for p in name_parts:\n",
    "                    if (len(n)>5) and (len(p)>5):\n",
    "                        if (edit_distance(n,p)<3):\n",
    "                            name_set.append(n)\n",
    "        \n",
    "        all_name_sets.append(name_set)\n",
    "        \n",
    "    return all_name_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts_cleaned = [cleanTextForNameSearch(x) for x in txts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if first part of shorter name is entirely contained in longer name\n",
    "fuzzy match to edit distance of two \n",
    "look at part of string length of shorter name - if those fuzzy match\n",
    "cut it off and group, check to see if second part is dictionary name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match known publishers\n",
    "remove publishers\n",
    "regex with name & name & name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num, txt in enumerate(txts_cleaned):\n",
    "    try:\n",
    "        print('Text #' + str(num))\n",
    "        for x in getSetOfNames(txt):\n",
    "            print(x)\n",
    "        print()\n",
    "    except:\n",
    "        print('Error')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
