{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ranked list of most likely names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../aps_reviews/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2645c0fd93d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading in files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../aps_reviews/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtxts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../aps_reviews/'"
     ]
    }
   ],
   "source": [
    "# loading in files\n",
    "directory = \"../../aps_reviews/\"\n",
    "filenames = os.listdir(directory)\n",
    "txts = []\n",
    "for file in filenames:\n",
    "    with open(directory + file) as f:\n",
    "        txts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_cleanup(string):\n",
    "    lowered = string.lower().split('|')[0]\n",
    "    new = \"\".join([u for u in lowered if u.isalpha() or u == ' '])\n",
    "    return \" \".join(new.split()[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_cleanup(string):\n",
    "    lowered = string.lower().split('|')[0]\n",
    "    no_parens = re.sub(\"\\(.+?\\)\", \"\", lowered)\n",
    "    no_parens = no_parens.rstrip(',')\n",
    "    no_parens = no_parens.rstrip(' ')\n",
    "    no_parens = no_parens.replace('.', '')\n",
    "    no_parens = no_parens.replace('[', '')\n",
    "    no_parens = no_parens.replace(']', '')\n",
    "    #split on comma, make first last\n",
    "    split = no_parens.split(',')\n",
    "    if type(split) == list:\n",
    "        head = split[0:1]\n",
    "        tail = split[1:]\n",
    "\n",
    "        final = \" \".join(tail+head)\n",
    "    else:\n",
    "        final = split\n",
    "    return final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_cleanup_last(string):\n",
    "    lowered = string.lower().split('|')[0]\n",
    "    no_parens = re.sub(\"\\(.+?\\)\", \"\", lowered)\n",
    "    no_parens = no_parens.rstrip(',')\n",
    "    no_parens = no_parens.rstrip(' ')\n",
    "    no_parens = no_parens.replace('.', '')\n",
    "    no_parens = no_parens.replace('[', '')\n",
    "    no_parens = no_parens.replace(']', '')\n",
    "    #split on comma, make first last\n",
    "    split = no_parens.split(',')\n",
    "    if type(split) == list:\n",
    "        \n",
    "        return split[0]\n",
    "    else:\n",
    "        return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_cleanup_first(string):\n",
    "    lowered = string.lower().split('|')[0]\n",
    "    no_parens = re.sub(\"\\(.+?\\)\", \"\", lowered)\n",
    "    no_parens = no_parens.rstrip(',')\n",
    "    no_parens = no_parens.rstrip(' ')\n",
    "    no_parens = no_parens.replace('.', '')\n",
    "    no_parens = no_parens.replace('[', '')\n",
    "    no_parens = no_parens.replace(']', '')\n",
    "    #split on comma, make first last\n",
    "    split = no_parens.split(',')\n",
    "    if type(split) == list:\n",
    "        first = split[-1].split()\n",
    "        try:\n",
    "            return first[0]\n",
    "        except:\n",
    "            return split[-1]\n",
    "    else:\n",
    "        return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get author and title list\n",
    "df_pre = pd.read_csv('fiction_metadata.csv', dtype={'oclc':'str','recordid':'str', 'datetype': 'str', 'startdate':'str' }).fillna('')\n",
    "df_pre = df_pre.loc[df_pre['date'].isin([str(u) for u in range(1878, 1926)])].reset_index(drop=True)\n",
    "\n",
    "df_post = pd.read_csv('fiction_metadata_post_1923.csv', dtype={'metadatasuspicious':'str'}).fillna('')\n",
    "df_post = df_post.loc[df_post['inferreddate'].isin([str(u) for u in range(1923, 1928)])].reset_index(drop=True)\n",
    "\n",
    "df_all = df_pre[['author', 'title', 'date']]\n",
    "df_post_new = df_post[['author', 'title', 'inferreddate']]\n",
    "df_post_new.rename(columns={'inferreddate':'date'}, inplace=True)\n",
    "df_all = df_all.append(df_post_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first five/six words, lowercase, remove special characters and punctuation\n",
    "df_all['title'] = df_all['title'].apply(title_cleanup)\n",
    "df_all['author_last'] = df_all['author'].apply(author_cleanup_last)\n",
    "df_all['author_first'] = df_all['author'].apply(author_cleanup_first)\n",
    "df_all['author_full'] = df_all['author'].apply(author_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedupe on author, title\n",
    "df_all = df_all.drop_duplicates(['author_full', 'title']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_by_last_name = {}\n",
    "\n",
    "#make a dictionary of lastnames\n",
    "for row in df_all.iterrows():\n",
    "    #make the value a list of first_names (ignore any that are one letter)\n",
    "    if len(row[1]['author_first']) > 2:\n",
    "        try:\n",
    "            author = authors_by_last_name[row[1]['author_last']]\n",
    "            if row[1]['author_first'] not in authors_by_last_name[row[1]['author_last']]:\n",
    "                if row[1]['author_first'] != row[1]['author_last']:\n",
    "                    authors_by_last_name[row[1]['author_last']].append(row[1]['author_first'])\n",
    "        except:\n",
    "            authors_by_last_name[row[1]['author_last']] = [row[1]['author_first']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_names = {}\n",
    "for name in authors_by_last_name.keys():\n",
    "    if len(authors_by_last_name[name]) == 1:\n",
    "        solo_names[name] = authors_by_last_name[name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(authors_by_last_name,open('author_last_name_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this function needs a lot of work!!!\n",
    "\n",
    "# 1. titles list is incomplete\n",
    "# 2. assumes surname will be one word\n",
    "# 3. returns empty if top last name not in author names dictionary \n",
    "# 4. returns empty if the last name is found but the first name isn't\n",
    "# 5. code to choose the most frequently mentioned last name / first name pair might be coded wrong\n",
    "# 6. current not check \n",
    "# 7. has no fuzziness ... in the example review we have \"Lucien Carr\", \"Mr. Carr\", \"and \"Ldclen Carr\"\n",
    "# So the algorithm could theoretically resolve to Lucien Carr since that's a name and Ldclen isn't\n",
    "# Lucien Carr isn't in the author names dictionary but we could program this to find top names not in the dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eva's edits round 1: trying symspell and names from the us census to correct OCR issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first i'm gonna need to combine the documents from every year\n",
    "name_dir = \"../../../Code_stuff/names/\"\n",
    "name_files = os.listdir(name_dir)\n",
    "len(name_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lists = []\n",
    "for file in name_files:\n",
    "    with open(name_dir + file, encoding='latin-1') as f:\n",
    "        name_lists.extend(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lists[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lists[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [x[:-1] for x in name_lists if len(x.split(','))==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list[0].split(',')[-1].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [x for x in name_list if x.split(',')[-1].isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [x for x in name_list if x.split(',')[0].isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [x for x in name_list if ''.join(x.split(',')).isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = pd.DataFrame(name_lists, columns = ['name_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def justName(name):\n",
    "    name_parts = name[:-1].split(',')\n",
    "    return name_parts[0]\n",
    "def justCount(name):\n",
    "    name_parts = name[:-1].split(',')\n",
    "    try:\n",
    "        return int(name_parts[-1])\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df['name'] = name_df.name_txt.map(justName)\n",
    "name_df['freq'] = name_df.name_txt.map(justCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = name_df[name_df.freq > 4][['name','freq']]\n",
    "name_df = name_df[name_df['name'].apply(lambda x: x.isalpha())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df[name_df.name == 'Emily'].aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = name_df.groupby('name').aggregate(np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['freq'] = grouped.freq.apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv('name_freq_dict.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity \n",
    "\n",
    "# maximum edit distance per dictionary precalculation\n",
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "# create object\n",
    "sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "# load dictionary\n",
    "dictionary_path = \"name_freq_dict.txt\"\n",
    "term_index = 0 \n",
    "count_index = 1\n",
    "sym_spell.load_dictionary(dictionary_path, term_index, count_index, separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = sym_spell.lookup(\"Ldclen\", Verbosity.CLOSEST,\n",
    "                               max_edit_distance=2, include_unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = suggestions[0]._term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_spell._words['Emily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test text\n",
    "mytext = \"\"\"\n",
    "    Missouri: A Bone of Contention '                 WE  aware that most of the States of the Union had their nicknames, more or less complimentary, but to name Missouri ' a bone of contention ' is a stroke of wit. It does, however, rightly describe the Missouri of the past, and vividly writes in a phrase her political history. Until the triumph of the Union armies and the close of the Civil War, Missouri was in the jaws of the watch-dogs of slavery and freedom. In war or in peace, the subiect of legislative com-                 promise or of military struggle, Missouri was an uncertain factor. Now, after -five years of national peace, her history may be calmly and impartially written. Indeed, the task has been done, and well done, and the , Lucien Carr of Harvard, may be congratulated upon his work,  is strong, unimpassioned, scholarly, and as impressed with the firm touch which comes of local knowledge as are the imprinted rocks in the cabinets at Cambridge. Long familiarity with the wealth of archaeology in the Peabody Museuml seems to have given him the power of comparison and generalization in the evolution of a commonwealth, while  acquaintance with living men enables him to blend the results of the study and the field in pleasing literary form. Five of his seventeen chapters give a luminous picture of the early French and Spanish discoveries and domination. Then follow three chapters treating of the                 Missouri. By Ldclen Carr. $ti... (American Commonwealths.) Boston:                 Itoughto., Sftfltn & Co.                 l , the compromise, and the  into the U nion of this State named after the great river which flows through it. In his treatment of the period from 1844 to i861, as well as that of war time, some readers may charge Mr. Carr with unduly favoring the Southern and even Confederate view; but to people living this side of the now-vanished Mason and Dixon's line, this is doubtless a benefit; for only when Northern people are able to ' put themselves in the place' of Southerners and see with Southern eyes, can they be sure that they have achieved that impartiality which is essential to the writing of final history. He shows that the Missourians were neither secessionists nor slavery propagandists. He both criticises and justifies the action of the second convention which, in the uncertain hours when other States  seceding and Missouri's Governor had been driven into exile, org  a provisional government, and  saved Missouri Irons ' the pit of political degradation into which the States in rebellion were sunk during the period of reconstruction.' Mr. Carr practically and almost abruptly ends his history at the close of the War, believing that the career of Missouri as a bone of contention ended with the abolition of slavery. The fifty years' struggle was over, the State recovered rapidly froni the wounds of the Civil War, wealth increased wonderfully, and the Negro was liberally dealt with in most if not all points relating to citizenship. Taken as a whole, this book, with its sustained interest, high average literary merit, and thorough treatment of the voluminous facts, fully justifies its place in the series of ' histories of such States as have exercised a positive influence in the shaping of the national Government, or have had a striking political - . . history.' Like the others, it has a good map and index.\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.findall('dr\\. .+? |rev\\. .+? |miss .+? |mr\\..+? |mrs\\..+? ', mytext.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [word.replace(\"'s\", \"\") for word in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) > 0:\n",
    "    top = Counter(results).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastname = top[0][0].split('.')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = \"\"\"Doctor,Dr,Mr,Mrs,Ms,Miss,Msgr,Monsignor,Rev,Reverend,Hon,Honorable,Honourable,Prof,Professor,Madame,Madam,Lady,Lord,Sir,Dame,Master,Mistress,Chancellor,Principal,President,Pres,Warden,Dean,Regent,Rector,Provost,Director\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.lower().rstrip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = r\"\\.? .+? |\".join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for x in titles:\n",
    "    query = r\"\\.? .+? \"\n",
    "    print(re.findall(x+query, mytext.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(title_list, mytext.lower())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLastName(text):\n",
    "    \"\"\"\n",
    "    Returns words following common \n",
    "    \"\"\"\n",
    "    results = re.findall('dr\\. .+? |rev\\. .+? |miss .+? |mr\\..+? |mrs\\..+? ', text.lower())\n",
    "    results = [word.replace(\"'s\", \"\") for word in results]\n",
    "    if len(results) > 0:\n",
    "        top = Counter(results).most_common(1)\n",
    "        return top[0][0].split('.')[-1].strip()\n",
    "    else:\n",
    "        raise Exception('no last names found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findLastName(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFirstName(text, lastname):\n",
    "    results = re.findall('dr\\. .+? |rev\\. .+? |miss .+? |mr\\..+? |mrs\\..+? ', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name_results = []\n",
    "\n",
    "au_first_names = authors_by_last_name[lastname]\n",
    "            \n",
    "for au_name in au_first_names:\n",
    "    first_name_matches = re.search(au_name, mytext.lower())\n",
    "    if first_name_matches:\n",
    "        first_name_results.append(au_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_author(text, name_dict):\n",
    "    \"\"\" This function looks at a block of text, possibly a book review, and \n",
    "    uses a dictionary of names to find the top first name and last name pair \n",
    "    mentioned in the text. A statistical method for name inference would probably \n",
    "    be preferable to this method\"\"\"\n",
    "\n",
    "    #get the most frequent mr or mrs., miss, dr in the review \n",
    "    #and all the characters after the honorific until the next space (non-greedy)    \n",
    "    results = re.findall('dr\\. .+? |rev\\. .+? |miss .+? |mr\\..+? |mrs\\..+? ', text.lower())\n",
    "    \n",
    "    #remove possessives\n",
    "    results = [word.replace(\"'s\", \"\") for word in results]\n",
    "    print(results)\n",
    "\n",
    "    if len(results) > 0:\n",
    "        top = Counter(results).most_common(1)\n",
    "\n",
    "        lastname = top[0][0].split('.')[-1].strip()\n",
    "            \n",
    "        #get authors with same last name\n",
    "        first_name_results = []\n",
    "        try:\n",
    "            au_first_names = authors_by_last_name[lastname]\n",
    "            \n",
    "            for au_name in au_first_names:\n",
    "                first_name_matches = re.search(au_name, text.lower())\n",
    "                if first_name_matches:\n",
    "                    first_name_results.append(au_name)\n",
    "            if len(first_name_results) > 0:\n",
    "                topfirst = Counter(first_name_results).most_common(1)\n",
    "                \n",
    "                firstname = topfirst[0][0]\n",
    "                \n",
    "            else:\n",
    "                firstname = ''\n",
    "        except:\n",
    "            firstname = ''\n",
    "        if firstname == '':\n",
    "            for i in both:\n",
    "                first_name_matches = re.search(i, text.lower())\n",
    "                if first_name_matches:\n",
    "                    first_name_results.append(i)\n",
    "            \n",
    "        #match a first name or pass\n",
    "        if len(lastname) > 4:\n",
    "            return [lastname, firstname]\n",
    "        else:\n",
    "            return [\"no match\", \"no match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_top_author(mytext, authors_by_last_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eva's edits round 2: trying to find words commonly preceding authors names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts[0][:300].lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_names = list(set(authors_by_last_name.keys()))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'|'.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_poss = title_list + r\". (.+)*?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_last_names = [title_poss+name for name in last_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_last_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'|'.join(title_last_names)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '|'.join(title_last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(pattern,mytext)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in [txt.lower().strip() for txt in txts]:\n",
    "    results = re.findall(pattern,doc)\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_by_last_name[lastname]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
